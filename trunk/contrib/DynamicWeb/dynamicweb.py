# -*- coding: utf-8 -*-
#
# Gramps - a GTK+/GNOME based genealogy program
#
# Copyright (C) 2014 Pierre BÃ©lissent
#
# This program is based on "narrativeweb.py" included in Gramps
# Copyrights for "narrativeweb.py":
# Copyright (C) 2000-2007  Donald N. Allingham
# Copyright (C) 2007       Johan Gonqvist <johan.gronqvist@gmail.com>
# Copyright (C) 2007-2009  Gary Burton <gary.burton@zen.co.uk>
# Copyright (C) 2007-2009  Stephane Charette <stephanecharette@gmail.com>
# Copyright (C) 2008-2009  Brian G. Matherly
# Copyright (C) 2008       Jason M. Simanek <jason@bohemianalps.com>
# Copyright (C) 2008-2011  Rob G. Healey <robhealey1@gmail.com>
# Copyright (C) 2010       Doug Blank <doug.blank@gmail.com>
# Copyright (C) 2010       Jakim Friant
# Copyright (C) 2010       Serge Noiraud
# Copyright (C) 2011       Tim G L Lyons
# Copyright (C) 2013       Benny Malengier
#
# This program embeds some ideas from "fanchart.py" included in Gramps
# Copyrights for "fanchart.py":
# Copyright (C) 2001-2007  Donald N. Allingham, Martin Hawlisch
# Copyright (C) 2009 Douglas S. Blank
# Copyright (C) 2012 Benny Malengier
# Copyright (C) 2013 Vassilii Khachaturov
#
# This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
#
# $Id: $

"""
Dynamic Web Report

This report could build a complete set of web pages that contain most of the database data.
See L{PAGES_NAMES} for the list of exported pages.
It is also possible to export custom pages: This pages are build from a specified Gramps note (see L{DynamicWebOptions.note_help}).

The generated pages use lots of Javascript:
 - The following Javascript frameworks are used:
   JQuery: jquery.com
   Bootstrap: getbootstrap.com
   DataTables: datatables.net
   Raphael: raphaeljs.com
 - The web pages have the following structure:
	- dwr_db_*.js: Generated files that contain the Gramps data. Theses files are generated by the methods "DynamicWebReport._export_***"
	- *.html: Generated HTML files.
	  See the list of HTML pages given in L{PAGES_NAMES}
	  Some files (not listed in in L{PAGES_NAMES}) are generated by L{DynamicWebReport._export_pages}
	- dwr_conf.js: Generated files that configures the scripts behavior, and localizes the scripts. See L{DynamicWebReport._export_script_configuration}
	- image: Directory containing images
	- thumb: Directory containing images thumbnails
	- data: Directory containing the web site template:
	  - dwr_start.js: entry point script. Loads the other scripts. Loads he CSS stylesheets. Contains general utility code.
	  - dwr.js: Main script
	  - dwr_body.js: Script for formating the pages appearance
	  - dwr_svg.js: Script for building the SVG graph
	  - dwr_styles.css: Base CSS stylesheet
	  - dwr_template.css: Template CSS stylesheet, for style that overwrtie the base styles in "dwr_styles.css"
	  
During the pages generation, the template files are copied into the destination directory.
The files in the destination directory are overwritten, unless the destination files are more recent than the template files.
	  
The pages format and layout is documented in "dwr_body.js"
The pages dynamic generation is documented in "dwr.js"
The pages graph generation is documented in "dwr_svg.js"


Classes:

 - DynamicWebReport: main class that produces the report
   Entry point to produce the report is write_report

 - DynamicWebOptions: class that defines the options and provides the handling interface

 """

#TODO: User documentation (wiki?)
#TODO: In the map use different colors for different events types.
#TODO: Other bootstrap templates, use LESS for css generation
#TODO: Sorting items (children, pages in citations, events, etc.)
#TODO: years in gregorian calendar (get_***_year)
#TODO: LDS stuff
#TODO: Show siblings
#TODO: Connection to other Gramps web reports. Connect it with Gramps HtmlView ?
#TODO: Index pages overflow the size of the page body. The "DataTables" responsive plugin has a bug. solution to be found.
#TODO: localize surnames first letter extraction (see first_letter in narrativeweb) maybe there is a Javascript library for that
#TODO: filter in datatables could be insensitive to accents
#TODO: export ISO dates
#TODO: approximative search

#TODO: Calendar page (see web calendar and calendar report)
#TODO: Statistic charts, + database summary

# For the SVG graph:
#TODO: Shrunk the fonts for the largest generation to fit it on the page (same font size for all the persons of the same generation)
#TODO: if possible, add a feature to expand/minimize branches of the graphs.
#TODO: Thumbnails and dates in graphs
#TODO: Add new graph styles, in order to have same renderings as:
#             Fan charts
#             Family lines, Hourglass, Relationship graphs
#             Ancestor, Descendant trees
#             Descendant lines

#------------------------------------------------
# python modules
#------------------------------------------------
from __future__ import print_function, division
from functools import partial
import os
import sys
import re
import copy
import time
import shutil
import codecs
import tarfile
import tempfile
import colorsys
if sys.version_info[0] < 3:
	from cStringIO import StringIO
	string_types = basestring
else:
	from io import StringIO
	string_types = str
from textwrap import TextWrapper
from unicodedata import normalize
from collections import defaultdict
from xml.sax.saxutils import escape
if (sys.version_info[0] < 3):
	import urlparse, urllib
else:
	import urllib, urllib.parse as urlparse
import zipfile

from operator import itemgetter
from decimal import Decimal, getcontext
getcontext().prec = 8


#------------------------------------------------
# Set up logging
#------------------------------------------------
import logging
log = logging.getLogger(".DynamicWeb")
# The log initialization shall be performed after Gramps start-up (i.e. not here)

#------------------------------------------------
# Gramps module
#------------------------------------------------


from gramps.gen.const import IMAGE_DIR, GRAMPS_LOCALE as glocale
try:
	_trans = glocale.get_addon_translator(__file__)
except ValueError:
	_trans = glocale.translation
_ = _trans.sgettext

from gramps.version import VERSION, VERSION_TUPLE
DWR_VERSION_410 = (VERSION_TUPLE[0] >= 4) and (VERSION_TUPLE[1] >= 1)
DWR_VERSION_412 = (VERSION_TUPLE[0] >= 4) and (VERSION_TUPLE[1] >= 1) and (VERSION_TUPLE[2] >= 2)
DWR_VERSION_420 = (VERSION_TUPLE[0] >= 4) and (VERSION_TUPLE[1] >= 2)
from gramps.gen.lib import (ChildRefType, Date, EventType, FamilyRelType, Name,
							NameType, Person, UrlType, NoteType,
							EventRoleType, Family, Event, Place, Source,
							Citation, MediaObject, Repository, Note, Tag,
							MediaRef, Location)
if (DWR_VERSION_410):
	from gramps.gen.lib import PlaceType
from gramps.gen.lib.date import Today
from gramps.gen.const import PROGRAM_NAME, URL_HOMEPAGE
from gramps.gen.plug.menu import (PersonOption, NumberOption, StringOption,
	BooleanOption, EnumeratedListOption, FilterOption,
	NoteOption, MediaOption, DestinationOption, ColorOption)
from gramps.gen.plug.report import (Report, Bibliography)
from gramps.gen.plug.report import utils as report_utils
from gramps.gen.plug.report import MenuReportOptions

from gramps.gen.utils.config import get_researcher
from gramps.gen.utils.string import conf_strings
from gramps.gen.utils.file import media_path_full
from gramps.gen.utils.alive import probably_alive
from gramps.gen.utils.db import get_source_and_citation_referents, get_birth_or_fallback, get_death_or_fallback, get_marriage_or_fallback
from gramps.gen.constfunc import win, conv_to_unicode, get_curr_dir
if (sys.version_info[0] < 3):
	from gramps.gen.constfunc import UNITYPE
else:
	UNITYPE = str
from gramps.gen.config import config
from gramps.gui.thumbnails import get_thumbnail_path, run_thumbnailer
from gramps.gen.utils.image import image_size, resize_to_jpeg_buffer
from gramps.gen.mime import get_description
from gramps.gen.display.name import displayer as _nd
if (DWR_VERSION_412):
	from gramps.gen.display.place import displayer as _pd
from gramps.gen.datehandler import get_date_formats, displayer as _dd
from gramps.gen.proxy import PrivateProxyDb, LivingProxyDb
from gramps.plugins.lib.libhtmlconst import _CHARACTER_SETS, _CC, _COPY_OPTIONS

# import HTML Class from src/plugins/lib/libhtml.py
from gramps.plugins.lib.libhtml import Html, xml_lang

# import styled notes from src/plugins/lib/libhtmlbackend.py
from gramps.plugins.lib.libhtmlbackend import HtmlBackend, process_spaces

from gramps.plugins.lib.libgedcom import make_gedcom_date, DATE_QUALITY

from gramps.plugins.webreport.narrativeweb import first_letter

from gramps.gen.utils.place import conv_lat_lon
from gramps.gui.pluginmanager import GuiPluginManager

from gramps.gen.relationship import get_relationship_calculator
if (DWR_VERSION_410):
	from gramps.gen.utils.location import get_main_location

from gramps.gui.widgets.fanchart import (
	GENCOLOR,
	GRADIENTSCALE,
	BACKGROUND_SCHEME1,
	BACKGROUND_SCHEME2,
	BACKGROUND_GENDER,
	BACKGROUND_WHITE,
	BACKGROUND_GRAD_GEN,
	BACKGROUND_GRAD_AGE,
	BACKGROUND_SINGLE_COLOR,
	BACKGROUND_GRAD_PERIOD,
)
from gramps.gui.utils import hex_to_rgb

SORT_KEY = glocale.sort_key

#------------------------------------------------
# constants
#------------------------------------------------

#: Maximum number of pages containing custom text
NB_CUSTOM_PAGES = 5
#: Maximum number of pages =
NB_TOTAL_PAGES_MAX = 15
#: Liste of the pages (description, title, file name)
PAGES_NAMES = [
	(_("Person page"), _("Person"), "person.html"),
	(_("Surnames index page"), _("Surnames"), "surnames.html"),
	(_("Individuals index page"), _("Individuals"), "persons.html"),
	(_("Families index page"), _("Families"), "families.html"),
	(_("Sources index page"), _("Sources"), "sources.html"),
	(_("Media index page"), _("Media"), "medias.html"),
	(_("Places index page"), _("Places"), "places.html"),
	(_("Addresses page"), _("Addresses"), "address.html"),
	(_("Repositories index page"), _("Repositories"), "repositories.html"),
	(_("SVG graphical tree"), _("Tree"), "tree_svg.html"),
] + [
	(_("Custom page %(index)i") % {"index": i + 1}, _("Custom"), "custom_%i.html" % (i + 1))
	for i in range(NB_CUSTOM_PAGES)
]

# Constants used as indexes in L{PAGES_NAMES}
(PAGE_PERSON,
PAGE_SURNAMES,
PAGE_PERSON_INDEX,
PAGE_FAMILY_INDEX,
PAGE_SOURCE_INDEX,
PAGE_MEDIA_INDEX,
PAGE_PLACE_INDEX,
PAGE_ADDRESS_INDEX,
PAGE_REPOSITORY_INDEX,
PAGE_SVG_TREE,
PAGE_CUSTOM) = range(11)

# List of the descriptions of the tree graphs types
SVG_TREE_TYPES = [
	_("Ascending tree"),
	_("Descending tree"),
	_("Descending tree with spouses"),
	_("Ascending and descending tree"),
	_("Ascending and descending tree with spouses"),
]
(SVG_TREE_TYPE_ASCENDING,
SVG_TREE_TYPE_DESCENDING,
SVG_TREE_TYPE_DESCENDING_SPOUSES,
SVG_TREE_TYPE_ASCDESC,
SVG_TREE_TYPE_ASCDESC_SPOUSES) = range(len(SVG_TREE_TYPES))
DEFAULT_SVG_TREE_TYPE = SVG_TREE_TYPE_ASCDESC

SVG_TREE_SHAPES = [
	_("Vertical (â)"),
	_("Vertical (â)"),
	_("Horizontal (â)"),
	_("Horizontal (â)"),
	_("Full Circle"),
	_("Half Circle"),
	_("Quadrant"),
]
(SVG_TREE_SHAPE_VERTICAL_TOP_BOTTOM,
SVG_TREE_SHAPE_VERTICAL_BOTTOM_TOP,
SVG_TREE_SHAPE_HORIZONTAL_LEFT_RIGHT,
SVG_TREE_SHAPE_HORIZONTAL_RIGHT_LEFT,
SVG_TREE_SHAPE_CIRCLE,
SVG_TREE_SHAPE_HALF_CIRCLE,
SVG_TREE_SHAPE_QUADRANT) = range(len(SVG_TREE_SHAPES))
DEFAULT_SVG_TREE_SHAPE = SVG_TREE_SHAPE_HORIZONTAL_LEFT_RIGHT

SVG_TREE_DISTRIB_ASC = [
	_('Size proportional to number of ancestors'),
	_('Homogeneous parents distribution'),
]
SVG_TREE_DISTRIB_DSC = [
	_('Size proportional to number of descendants'),
	_('Homogeneous children distribution'),
]
(SVG_TREE_DISTRIB_PROPORTIONAL,
SVG_TREE_DISTRIB_HOMOGENEOUS) = range(len(SVG_TREE_DISTRIB_ASC))
DEFAULT_SVG_TREE_DISTRIB = SVG_TREE_DISTRIB_PROPORTIONAL

SVG_TREE_BACKGROUNDS = [
	_('Gender colors'),
	_('Generation based gradient'),
	_('Age based gradient'),
	_('Single main (filter) color'),
	_('Time period based gradient'),
	_('White'),
	_('Color scheme classic report'),
	_('Color scheme classic view'),
]
(SVG_TREE_BACKGROUND_GENDER,
SVG_TREE_BACKGROUND_GENERATION,
SVG_TREE_BACKGROUND_AGE,
SVG_TREE_BACKGROUND_SINGLE,
SVG_TREE_BACKGROUND_PERIOD,
SVG_TREE_BACKGROUND_WHITE,
SVG_TREE_BACKGROUND_SCHEME1,
SVG_TREE_BACKGROUND_SCHEME2) = range(len(SVG_TREE_BACKGROUNDS))
DEFAULT_SVG_TREE_BACKGROUND = SVG_TREE_BACKGROUND_GENERATION

#: Templates for the website, in the form: [directory, name]
#  First template is the default one:
#  The files in the default template are used when they are not present in another template
#  Only the files that are different from the default template are present in the other templates directories
WEB_TEMPLATE_LIST = (
	("dwr_default", _("Default")),
	("dwr_mainz", _("Mainz")),
)


INCLUDE_LIVING_VALUE = 99 #: Arbitrary number

# Indexes in the L{DynamicWebReport.obj_dict} and L{DynamicWebReport.bkref_dict} elements
OBJDICT_NAME = 0
OBJDICT_GID = 1
OBJDICT_INDEX = 2
BKREF_CLASS = 0
BKREF_HANDLE = 1
BKREF_REFOBJ = 2


_html_dbl_quotes = re.compile(r'([^"]*) " ([^"]*) " (.*)', re.VERBOSE)
_html_sng_quotes = re.compile(r"([^']*) ' ([^']*) ' (.*)", re.VERBOSE)

def html_escape(text):
	"""Convert the text and replace some characters with a &# variant."""
	# First single characters, no quotes
	text = escape(text)
	# Deal with double quotes.
	m = _html_dbl_quotes.match(text)
	while m:
		text = "%s" "&#8220;" "%s" "&#8221;" "%s" % m.groups()
		m = _html_dbl_quotes.match(text)
	# Replace remaining double quotes.
	text = text.replace('"', '&#34;')
	# Deal with single quotes.
	text = text.replace("'s ", '&#8217;s ')
	m = _html_sng_quotes.match(text)
	while m:
		text = "%s" "&#8216;" "%s" "&#8217;" "%s" % m.groups()
		m = _html_sng_quotes.match(text)
	# Replace remaining single quotes.
	text = text.replace("'", '&#39;')

	return text


def script_escape(text):
	"""Convert the text and escape quotes, backslashes and end-of-lines
	"""
	return(text.
		replace("\\", "\\\\").
		replace("'", "\\'").
		replace("\"", "\\\"").
		replace("\n", "\\n")
	)


def html_text(html):
	"""Get the string corresponding to an L{Html} object"""
	if (isinstance(html, string_types)): return(html.strip())
	sw = StringIO()
	html.write(partial(print, file = sw), indent = "", tabs = "")
	return(sw.getvalue().strip())


def format_date(date, gedcom = False, iso = False):
	"""Give the date as a string
	@param iso: If True, the date should be given in ISO format: YYYY-MM-DD
	@type iso: Boolean
	"""
	if (not date): return("")
	
	val = ""
	
	if (iso):
		# TODO: export ISO dates
		# if (iso): val = DateDisplay.display(date) or ""
		# else: val = _dd.display(date) or ""
		pass
		
	elif (gedcom):
		start = date.get_start_date()
		if start != Date.EMPTY:
			cal = date.get_calendar()
			mod = date.get_modifier()
			quality = date.get_quality()
			if quality in DATE_QUALITY:
				qual_text = DATE_QUALITY[quality] + " "
			else:
				qual_text = ""
			if mod == Date.MOD_SPAN:
				val = "%sFROM %s TO %s" % (
					qual_text,
					make_gedcom_date(start, cal, mod, None), 
					make_gedcom_date(date.get_stop_date(), cal, mod, None))
			elif mod == Date.MOD_RANGE:
				val = "%sBET %s AND %s" % (
					qual_text,
					make_gedcom_date(start, cal, mod, None), 
					make_gedcom_date(date.get_stop_date(), cal, mod, None))
			else:
				val = make_gedcom_date(start, cal, mod, quality)
				
	else:
		# Regular Gramps place displayer
		val = _dd.display(date) or ""
	
	return(val)


def rmtree_fix(dirname):
	"""Windows fix: Python shutil.rmtree does not work properly on Windows.
	Unfortunately this fix is not completely working. Don't know why.
	The strategy is to rename the directory first, in order to let Windows delete it in differed time.
	"""
	#TODO: Fix shutil.rmtree on Windows
	tmp = dirname + "_removetree_tmp"
	os.rename(dirname, tmp)
	shutil.rmtree(tmp)
	# Wait for rmtree to complete
	for i in range(100):
		if (not os.path.exists(tmp)): break
		time.sleep(0.1)



class DynamicWebReport(Report):
	"""
	Class DynamicWebReport
	
	Extracts information from the database and exports the data into Javascript and HTML files
	
	The database extraction is performed by the method L{_build_obj_dict}. It recursively calls the methods "_add_***".
	
	The database extraction builds:
	 - indexes of the objects selected for the report as dictionaries,
	 - for each object (of the report), references to the objects calling this object.
	 
	The indexes of the objects selected are stored as dictionaries "obj_dict[class][handle]",
	indexed by the object class,
	indexed by the database handle,
	containing for each report object the following information:
	 - object file name, if any,
	 - object name,
	 - gramps id,
	 - object index, starting from 0,
	   only counting the objects selected,
	   each object type is counted separately.
	
	The references to objects are stored as dictionaries "bkref_dict[class][handle]",
	indexed by the object class,
	indexed by the database handle,
	containing for each report object the following information:
	 - class of the object referencing it,
	 - handle of the object referencing it,
	 - reference object (MediaRef, EventRef) if any.
	 
	The report is generated by L{write_report}
	"""

	def __init__(self, database, options, user):
		"""
		Create WebReport object that produces the report.

		The arguments are:

		database - the Gramps database instance
		options - instance of the Options class for this report
		user - instance of a gen.user.User()
		"""

		Report.__init__(self, database, options, user)
		self.user = user
		menu = options.menu
		self.link_prefix_up = True
		self.options = {}

		for optname in menu.get_all_option_names():
			menuopt = menu.get_option_by_name(optname)
			self.options[optname] = menuopt.get_value()

		if not self.options['incpriv']:
			self.database = PrivateProxyDb(database)
		else:
			self.database = database

		livinginfo = self.options['living']
		yearsafterdeath = self.options['yearsafterdeath']

		if livinginfo != INCLUDE_LIVING_VALUE:
			self.database = LivingProxyDb(self.database, livinginfo, None, yearsafterdeath)

		filters_option = menu.get_option_by_name('filter')
		self.filter = filters_option.get_filter()

		self.target_path = self.options['target'] #: Destination directory
		self.ext = ".html" #: HTML fiules extension
		self.title = self.options['title'] #: Web site title. Web pages title are in the form "title of the page - title of the site"

		self.author = get_researcher().get_name() #: Database author name. Used in copyright text.
		if self.author:
			self.author = self.author.replace(',,,', '')

		# The following data are local copies of the options. Refer to the L{DynamicWebOptions} class for more details.
		self.inc_events = self.options['inc_events']
		self.inc_places = self.options['inc_places']
		self.inc_families = self.options['inc_families']
		self.inc_gallery = self.options['inc_gallery']
		self.copy_media = self.options['copy_media']
		self.inc_notes = self.options['inc_notes']
		self.print_notes_type = self.options['print_notes_type']
		self.inc_sources = self.options['inc_sources']
		self.inc_repositories = self.options['inc_repositories']
		# Repositories are not exported unless sources are exported
		self.inc_repositories = self.inc_repositories and self.inc_sources
		self.inc_addresses = self.options['inc_addresses']
		self.name_format = self.options['name_format']
		self.short_name_format = self.options['short_name_format']
		self.encoding = self.options['encoding']
		self.copyright = self.options['copyright']
		self.inc_gendex = self.options['inc_gendex']
		self.template = self.options['template']
		self.pages_number = self.options['pages_number']
		self.page_content = [
			self.options['page_content_%i' %i]
			for i in range(self.pages_number)
		]
		self.page_name = [
			self.options['page_name_%i' %i]
			for i in range(len(PAGES_NAMES))
		]
		self.custom_menu = [
			self.options['custom_menu_%i' %i]
			for i in range(NB_CUSTOM_PAGES)
		]
		self.custom_note = [
			self.options['custom_note_%i' %i]
			for i in range(NB_CUSTOM_PAGES)
		]
		# Filter pages that cannot be exported due to other options
		self.page_content = [pc for pc in self.page_content if (not(
			(pc == PAGE_FAMILY_INDEX and not self.inc_families) or
			(pc == PAGE_MEDIA_INDEX and not self.inc_gallery) or
			(pc == PAGE_SOURCE_INDEX and not self.inc_sources) or
			(pc == PAGE_REPOSITORY_INDEX and not self.inc_repositories) or
			(pc == PAGE_PLACE_INDEX and not self.inc_places)
		))]
		self.pages_number = len(self.page_content)

		self._backend = HtmlBackend()
		self._backend.build_link = self.build_link
		
		# Data needed to compute colors gradients
		self.min_age = 0
		self.max_age = 0
		self.min_period = 1e10
		self.max_period = -1e10


	def write_report(self):
		"""
		Report generation
		"""
		
		# Initialize the logger
		# This initialization shall be performed after Gramps has start-up
		# import importlib
		# logging = importlib.reload(logging)
		# global log
		# log = logging.getLogger(".DynamicWeb")
		
		# Create directory
		dir_name = self.target_path
		if dir_name is None:
			dir_name = get_curr_dir()
		elif not os.path.isdir(dir_name):
			parent_dir = os.path.dirname(dir_name)
			if not os.path.isdir(parent_dir):
				msg = _("Neither %(current)s nor %(parent)s are directories") % \
					  {'current': dir_name, 'parent': parent_dir}
				self.user.notify_error(msg)
				return
			else:
				try:
					os.mkdir(dir_name)
				except IOError as value:
					msg = _("Could not create the directory: %(path)s") % {
						  "path": dir_name + "\n" + value[1]}
					self.user.notify_error(msg)
					return
				except:
					msg = _("Could not create the directory: %(path)s") % {"path":  dir_name}
					self.user.notify_error(msg)
					return
		config.set('paths.website-directory', os.path.dirname(self.target_path) + os.sep)


		# for use with discovering biological, half, and step siblings for use
		# in display_ind_parents()...
		# self.rel_class = get_relationship_calculator()

		#: List of images already copied
		self.images_copied = set()

		#: List of thumbnails already created
		self.thumbnail_created = set()

		#################################################
		# Pass 1 Build the lists of objects to be output

		self._build_obj_dict()
		self._sort_obj_dict()

		#################################################
		# Pass 2 Generate the web pages
		
		with self.user.progress(_("Dynamic Web Site Report"), _("Exporting family tree data ..."), 10) as step:
			self.created_files = []
			# Create directories
			for dirname in ["thumb"] + (["image"] if (self.copy_media) else []):
				dirpath = os.path.join(self.target_path, dirname)
				if (not os.path.isdir(dirpath)): os.mkdir(dirpath)
			# Copy web site files
			self.copy_template_files()
			step()
			# Export database as Javascript files
			self._export_individuals()
			step()
			self._export_families()
			step()
			self._export_sources()
			self._export_citations()
			self._export_repositories()
			step()
			self._export_places()
			step()
			self._export_media()
			step()
			self._export_surnames()
			step()
			# Generate HTML files
			self._export_pages()
			step()
			# Create GENDEX file
			self.build_gendex(self.obj_dict[Person])
			step()
			# Create an archive file of the web site
			self.create_archive()
			step()


	def _export_individuals(self):
		"""
		Export individuals data in Javascript file
		The individuals data is stored in the Javascript Array "I"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'I' is sorted by person name\n"
			"// 'I' gives for individual:\n"
			"//   - Gramps ID\n"
			"//   - The complete name\n"
			"//   - The short name\n"
			"//   - The names as a list of:\n"
			"//       [full name, type, title, nick, call, given, suffix, list of surnames, family nickname,\n"
			"//        notes, list of the name source citations index (in table 'C')]\n"
			"//   - The gender\n"
			"//   - The birth year in the form '1700', '?' (date unknown)\n"
			"//   - The birth place\n"
			"//   - The death year in the form '1700', '?' (date unknown), '' (not dead)\n"
			"//   - The death place\n"
			"//   - The death age\n"
			"//   - A list of events, with for each event:\n"
			"//       - The event name\n"
			"//       - The event date\n"
			"//       - The event date in ISO format (sortable)\n"
			"//       - The event place index (in table 'P'), -1 if none\n"
			"//       - The event description\n"
			"//       - The event text and notes (including event reference notes)\n"
			"//       - A list of the event media index, in the form:\n"
			"//           - media index (in table 'M')\n"
			"//           - media thumbnail path\n"
			"//           - [x1, y1, x2, y2] of the media reference\n"
			"//           - notes of the media reference\n"
			"//           - list of the media reference source citations index (in table 'C')\n"
			"//       - A list of the event source citations index (in table 'C')\n"
			"//   - A list of addresses, with for each address:\n"
			"//       - The address date\n"
			"//       - The address date in ISO format (sortable)\n"
			"//       - The address place in the form:\n"
			"//           [street, locality, parish, city, state, county, zip, country]\n"
			"//       - The address notes\n"
			"//       - A list of the address source citations index (in table 'C')\n"
			"//   - The person notes\n"
			"//   - A list of the person media references, in the form:\n"
			"//       - media index (in table 'M')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the person source citations index (in table 'C')\n"
			"//   - The list of the person attributes in the form:\n"
			"//       [attribute, value, note, list of citations]\n"
			"//   - The list of the person URL in the form:\n"
			"//       [type, url, description]\n"
			"//   - A list of partners families index (in table 'F')\n"
			"//   - A list of parents families in the form:\n"
			"//       [index (in table 'F'), relation to father, relation to mother, notes, list of citations]\n"
			"//   - A list of associations in the form:\n"
			"//       [person index (in table 'I'), relationship, notes, list of citations (in table 'C')]\n"
			"I = [")
		sep = "\n"
		person_list = list(self.obj_dict[Person].keys())
		person_list.sort(key = lambda x: self.obj_dict[Person][x][OBJDICT_INDEX])
		for person_handle in person_list:
			person = self.database.get_person_from_handle(person_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Person][person_handle][OBJDICT_GID] + "\",")
			# Names
			name = self.get_name(person) or ""
			sw.write("\"" + script_escape(name) + "\",")
			name = self.get_short_name(person) or ""
			sw.write("\"" + script_escape(name) + "\",\n")
			sw.write(self.get_name_data(person) + ",\n")
			# Gender
			gender = ""
			if (person.get_gender() == Person.MALE): gender = "M"
			if (person.get_gender() == Person.FEMALE): gender = "F"
			if (person.get_gender() == Person.UNKNOWN): gender = "U"
			sw.write("\"" + gender + "\",")
			# Years
			sw.write("\"" + self.get_birth_year(person) + "\",\n")
			sw.write("\"" + self.get_birth_place(person) + "\",\n")
			sw.write("\"" + self.get_death_year(person) + "\",\n")
			sw.write("\"" + self.get_death_place(person) + "\",\n")
			# Age at death
			sw.write("\"" + script_escape(self.get_death_age(person)) + "\",\n")
			# Events
			sw.write("[\n" + self._data_events(person) + "\n],\n")
			# Addresses
			sw.write("[\n" + self._data_addresses(person) + "\n],\n")
			# Get individual notes
			sw.write("\"" + script_escape(self.get_notes_text(person)) + "\",\n")
			# Get individual media
			sw.write(self._data_media_reference_index(person))
			sw.write(",\n")
			# Get individual sources
			sw.write(self._data_source_citation_index(person))
			sw.write(",\n")
			# Get individual attributes
			sw.write(self._data_attributes(person))
			sw.write(",\n")
			# Get individual URL
			sw.write(self._data_url_list(person))
			sw.write(",\n")
			# Families (partners)
			sw.write(self._data_families_index(person))
			sw.write(",\n")
			# Families (parents)
			sw.write(self._data_parents_families_index(person))
			sw.write(",\n")
			# Associations
			sw.write(self._data_associations(person))
			sw.write("\n]")
			#
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_indi.js", sw.getvalue())


	def get_name_data(self, person):
		primary_name = person.get_primary_name()
		all_names = [primary_name] + person.get_alternate_names()
		first_name = primary_name.get_first_name()
		text = "["
		sep = ""
		for name in all_names:
			text += sep + "["
			name.set_display_as(self.name_format)
			pname = _nd.display_name(name)
			text += "\"" + script_escape(pname) + "\","
			# Type
			text += "\"" + script_escape(str(name.get_type())) + "\","
			# Title
			title = name.get_title() or ""
			text += "\"" + script_escape(str(title)) + "\","
			# Nickname
			nick_name = name.get_nick_name()
			if (nick_name == first_name or not nick_name): nick_name = ""
			text += "\"" + script_escape(str(nick_name)) + "\","
			# Callname
			call_name = name.get_call_name()
			if (call_name == first_name or not call_name): call_name = ""
			text += "\"" + script_escape(str(call_name)) + "\","
			# Given
			given = name.get_first_name() or ""
			text += "\"" + script_escape(str(given)) + "\","
			# Suffix
			suffix = name.get_suffix() or ""
			text += "\"" + script_escape(str(suffix)) + "\","
			# Surnames
			surnames = name.get_surname_list()
			text += "[" + ",".join([
				"\"" + script_escape(str(surname.get_surname() or "")) + "\""
				for surname in surnames]) + "],"
			# Family nickname
			fnick = name.get_family_nick_name() or ""
			text += "\"" + script_escape(str(fnick)) + "\","
			# Get name date
			datetext = format_date(name.date) or ""
			text += "\"" + script_escape(datetext) + "\","
			# Get name notes
			text += "\"" + script_escape(self.get_notes_text(name)) + "\","
			# Get name sources
			text += self._data_source_citation_index(name) + "]"
			sep = ","
		text += "]"
		return(text)


	def get_name_object(self, person, maiden_name = None):
		"""
		Return person's name, unless maiden_name given, unless married_name
		listed.
		@param: person -- person object from database
		@param: maiden_name -- Female's family surname
		"""
		# Get all of a person's names
		primary_name = person.get_primary_name()
		married_name = None
		names = [primary_name] + person.get_alternate_names()
		for name in names:
			if int(name.get_type()) == NameType.MARRIED:
				married_name = name
				break # use first
		# Now, decide which to use:
		if maiden_name is not None:
			if married_name is not None:
				name = Name(married_name)
			else:
				name = Name(primary_name)
				surname_obj = name.get_primary_surname()
				surname_obj.set_surname(maiden_name)
		else:
			name = Name(primary_name)
		return(name)


	def get_name(self, person, maiden_name = None):
		name = self.get_name_object(person, maiden_name)
		name.set_display_as(self.name_format)
		return _nd.display_name(name)


	def get_short_name(self, person, maiden_name = None):
		name = self.get_name_object(person, maiden_name)
		name.set_display_as(self.short_name_format)
		return _nd.display_name(name)


	def _export_families(self):
		"""
		Export families data in Javascript file
		The families data is stored in the Javascript Array "F"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'F' is sorted by family full name\n"
			"// 'F' gives for each family:\n"
			"//   - Gramps ID\n"
			"//   - The family full name\n"
			"//   - The family union type\n"
			"//   - The marriage year in the form '1700', '?' (unknown), or '' (not married)\n"
			"//   - The marriage place"
			"//   - A list of events, with for each event:\n"
			"//       - The event name\n"
			"//       - The event date\n"
			"//       - The event date in ISO format (sortable)\n"
			"//       - The event place index (in table 'P'), -1 if none\n"
			"//       - The event description\n"
			"//       - The event text and notes (including event reference notes)\n"
			"//       - A list of the event media references, in the form:\n"
			"//           - media index (in table 'M')\n"
			"//           - media thumbnail path\n"
			"//           - [x1, y1, x2, y2] of the media reference\n"
			"//           - notes of the media reference\n"
			"//           - list of the media reference source citations index (in table 'C')\n"
			"//       - A list of the event source citations index (in table 'C')\n"
			"//   - The family notes\n"
			"//   - A list of the family media references, in the form:\n"
			"//       - media index (in table 'M')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the family source citations index (in table 'C')\n"
			"//   - The list of the family attributes in the form:\n"
			"//       [attribute, value, note, list of citations]\n"
			"//   - A list of spouses index (in table 'I')\n"
			"//   - A list of child in the form:\n"
			"//       [index (in table 'I'), relation to father, relation to mother, notes, list of citations]\n"
			"F = [")
		sep = "\n"
		family_list = list(self.obj_dict[Family].keys())
		family_list.sort(key = lambda x: self.obj_dict[Family][x][OBJDICT_INDEX])
		for family_handle in family_list:
			family = self.database.get_family_from_handle(family_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Family][family_handle][OBJDICT_GID] + "\",")
			# Names
			name = self.get_family_name(family) or ""
			sw.write("\"" + script_escape(name) + "\",\n")
			sw.write("\"" + script_escape(str(family.get_relationship())) + "\",\n")
			# Years
			sw.write("\"" + self.get_marriage_year(family) + "\",\n")
			sw.write("\"" + self.get_marriage_place(family) + "\",\n")
			# Events
			sw.write("[\n" + self._data_events(family) + "\n],\n")
			# Get family notes
			sw.write("\"" + script_escape(self.get_notes_text(family)) + "\",\n")
			# Get family media
			sw.write(self._data_media_reference_index(family))
			sw.write(",\n")
			# Get family sources
			sw.write(self._data_source_citation_index(family))
			sw.write(",\n")
			# Get family attributes
			sw.write(self._data_attributes(family))
			sw.write(",\n")
			# Partners
			sw.write(self._data_partners_index(family))
			sw.write(",\n")
			# Children
			sw.write(self._data_children_index(family))
			sw.write("\n]")
			#
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_fam.js", sw.getvalue())


	def _data_events(self, object):
		"""
		Build events data related to L{object} in a string representing a Javascript Array
		L{object} could be: a person or a family
		@return: events as a string representing a Javascript Array
		"""
		# Builds an event list that gives for each event:
		#  - Gramps ID\n"
		#  - The event name
		#  - The event date
		#  - The event date in ISO format (sortable)
		#  - The event place index (in table 'P'), -1 if none
		#  - The event description
		#  - The event text and notes (including event reference notes)
		#  - A list of the event media index, in the form:
		#      - media index (in table 'M')
		#      - media thumbnail path
		#      - [x1, y1, x2, y2] of the media reference
		#      - notes of the media reference
		#      - list of the media reference source citations index (in table 'C')\n"
		#  - A list of the event source citations index (in table 'C')
		event_ref_list = object.get_event_ref_list()
		if not event_ref_list: return("")
		rows = []
		for event_ref in event_ref_list:
			if (event_ref.ref not in self.obj_dict[Event]): continue
			event = self.database.get_event_from_handle(event_ref.ref)
			if (not event): continue
			trow = "\t["
			evt_type = str(event.get_type())
			event_role = event_ref.get_role()
			if (event_role != EventRoleType.PRIMARY and event_role != EventRoleType.FAMILY):
				evt_type += " (%s)" % event_role
			place_index = -1
			place_handle = event.get_place_handle()
			if (place_handle and (place_handle in self.obj_dict[Place])):
				place_index = self.obj_dict[Place][place_handle][OBJDICT_INDEX]
			evt_desc = event.get_description()
			trow += "\"" + self.obj_dict[Event][event_ref.ref][OBJDICT_GID] + "\","
			trow += "\"" + script_escape(html_escape(evt_type)) + "\","
			evt_date = format_date(event.get_date_object())
			trow += "\"" + script_escape(html_escape(evt_date)) + "\","
			evt_date = format_date(event.get_date_object(), True)
			trow += "\"" + script_escape(html_escape(evt_date)) + "\","
			trow += str(place_index) + ","
			if (evt_desc is None): evt_desc = ""
			trow += "\"" + script_escape(html_escape(evt_desc)) + "\","
			# Get event notes
			notelist = event.get_note_list()
			notelist.extend(event_ref.get_note_list())
			attrlist = event.get_attribute_list()
			attrlist.extend(event_ref.get_attribute_list())
			trow += "\"" + script_escape(self.get_notes_attributes_text(notelist, attrlist)) + "\","
			# Get event media
			trow += self._data_media_reference_index(event)
			trow += ","
			# Get event sources
			citationlist = event.get_citation_list()
			citationlist.extend(event_ref.get_citation_list())
			for attr in attrlist: citationlist.extend(attr.get_citation_list())
			trow += self._data_source_citation_index_from_list(citationlist)
			#
			trow += "]"
			rows.append(trow)
		return(",\n".join(rows))


	def _data_addresses(self, object):
		"""
		Export addresses data related to L{object} in a string representing a Javascript Array
		L{object} could be: a person or a repository
		@return: events as a string representing a Javascript Array
		"""
		# Builds an address list that gives for each address:
		#  - The address date\n"
		#  - The address date in ISO format (sortable)\n"
		#  - The address place in the form:\n"
		#      [street, locality, parish, city, state, county, zip, country]\n"\n"
		#  - The address notes\n"
		#  - A list of the address source citations index (in table 'C')\n"
		if (not self.inc_addresses): return("")
		addrlist = object.get_address_list()
		if not addrlist: return("")
		rows = []
		for addr in addrlist:
			text = "\t["
			addr_date = format_date(addr.get_date_object())
			text += "\"" + script_escape(html_escape(addr_date)) + "\","
			addr_date = format_date(addr.get_date_object(), True)
			text += "\"" + script_escape(html_escape(addr_date)) + "\","
			addr_data = [
				addr.get_street(),
				addr.get_locality(),
				"",
				addr.get_city(),
				addr.get_state(),
				addr.get_county(),
				addr.get_postal_code(),
				addr.get_country(),
				addr.get_phone(),
			]
			text += "[\"" + "\",\"".join([script_escape(data) for data in addr_data]) + "\"],"
			# Get address notes
			text += "\"" + script_escape(self.get_notes_text(addr)) + "\","
			# Get address sources
			text += self._data_source_citation_index(addr) + "]"
			rows.append(text)
		return(",\n".join(rows))


	def _export_sources(self):
		"""
		Export sources data in Javascript file
		The sources data is stored in the Javascript Array "S"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'S' is sorted by source title\n"
			"// 'S' gives for each source:\n"
			"//   - Gramps ID\n"
			"//   - The source title\n"
			"//   - The source text (author, etc.)\n"
			"//   - The source notes\n"
			"//   - A list of the source media references, in the form:\n"
			"//       - media index (in table 'M')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the citations index (in table 'C') referencing this source\n"
			"//   - A list of the repositories for this source, in the form:\n"
			"//       - repository index (in table 'R')\n"
			"//       - media type\n"
			"//       - call number\n"
			"//       - notes of the repository reference\n"
			"//   - The list of the sources attributes in the form:\n"
			"//       [attribute, value, note, list of citations]\n"
			"S = [")
		sep = "\n"
		source_list = list(self.obj_dict[Source])
		if (not self.inc_sources): source_list = []
		source_list.sort(key = lambda x: self.obj_dict[Source][x][OBJDICT_INDEX])
		for source_handle in source_list:
			source = self.database.get_source_from_handle(source_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Source][source_handle][OBJDICT_GID] + "\",")
			title = source.get_title() or ""
			sw.write("\"" + script_escape(html_escape(title)) + "\",\n")
			sw.write("\"")
			for (label, value) in [
				(_("Author"), source.get_author()),
				(_("Abbreviation"), source.get_abbreviation()),
				(_("Publication information"), source.get_publication_info())]:
				if value:
					html = Html("p") + Html("b", label + ": ") + value
					sw.write(script_escape(html_text(html)))
			sw.write("\",\n")
			# Get source notes
			sw.write("\"" + script_escape(self.get_notes_text(source)) + "\",\n")
			# Get source media
			sw.write(self._data_media_reference_index(source))
			sw.write(",\n")
			# Get source citations
			sw.write(self._data_bkref_index(Source, source_handle, Citation))
			sw.write(",\n")
			# Get repositories references
			sw.write(self._data_repo_reference_index(source))
			sw.write(",\n")
			# Get source attributes
			if (DWR_VERSION_410):
				sw.write(self._data_attributes_src(source))
			else:
				sw.write("[]")
			sw.write("\n]")
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_sour.js", sw.getvalue())


	def _export_citations(self):
		"""
		Export citations data in Javascript file
		The citations data is stored in the Javascript Array "C"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'C' gives for each source citation:\n"
			"//   - Gramps ID\n"
			"//   - The source index (in table 'S')\n"
			"//   - The citation text (page, etc.)\n"
			"//   - The citation notes\n"
			"//   - A list of the citation media references, in the form:\n"
			"//       - media index (in table 'M')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//   - A list of the person index (in table 'I') referencing this citation\n"
			"//     (including the person events referencing this citation)\n"
			"//   - A list of the family index (in table 'F') referencing this citation\n"
			"//     (including the family events referencing this citation)\n"
			"//   - A list of the media index (in table 'M') referencing this citation\n"
			"//     (including the media references referencing this citation)\n"
			"//   - A list of the place index (in table 'P') referencing this citation\n"
			"//     (including the media references referencing this citation)\n"
			"//   - A list of the repository index (in table 'R') referencing this citation\n"
			"C = [")
		sep = "\n"
		citation_list = list(self.obj_dict[Citation])
		if (not self.inc_sources): citation_list = []
		citation_list.sort(key = lambda x: self.obj_dict[Citation][x][OBJDICT_INDEX])
		for citation_handle in citation_list:
			citation = self.database.get_citation_from_handle(citation_handle)
			source_handle = citation.get_reference_handle()
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Citation][citation_handle][OBJDICT_GID] + "\",")
			sw.write(str(self.obj_dict[Source][source_handle][OBJDICT_INDEX])+ ",\n")
			sw.write("\"")
			confidence = citation.get_confidence_level()
			if ((confidence in conf_strings) and confidence != Citation.CONF_NORMAL):
				confidence = _(conf_strings[confidence])
			else:
				confidence = None
			for (label, value) in [
				(_("Date"), format_date(citation.get_date_object())),
				(_("Page"), citation.get_page()),
				(_("Confidence"), confidence),
			]:
				if value:
					html = Html("p") + Html("b", label + ": ") + value
					sw.write(script_escape(html_text(html)))
			sw.write("\",\n")
			# Get citation notes
			sw.write("\"" + script_escape(self.get_notes_text(citation)) + "\",\n")
			# Get citation media
			sw.write(self._data_media_reference_index(citation))
			sw.write(",\n")
			# Get references
			sw.write(self._data_bkref_index(Citation, citation_handle, Person))
			sw.write(",\n")
			sw.write(self._data_bkref_index(Citation, citation_handle, Family))
			sw.write(",\n")
			sw.write(self._data_bkref_index(Citation, citation_handle, MediaObject))
			sw.write(",\n")
			sw.write(self._data_bkref_index(Citation, citation_handle, Place))
			sw.write(",\n")
			sw.write(self._data_bkref_index(Citation, citation_handle, Repository))
			sw.write("\n]")
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_cita.js", sw.getvalue())


	def _export_repositories(self):
		"""
		Export repositories data in Javascript file
		The repositories data is stored in the Javascript Array "R"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'R' is sorted by repository name\n"
			"// 'R' gives for each repository:\n"
			"//   - Gramps ID\n"
			"//   - The repository name\n"
			"//   - The repository type\n"
			"//   - A list of addresses, with for each address:\n"
			"//       - The address date\n"
			"//       - The address date in ISO format (sortable)\n"
			"//       - The address place in the form:\n"
			"//           [street, locality, parish, city, state, county, zip, country]\n"
			"//       - The address notes\n"
			"//       - A list of the address source citations index (in table 'C')\n"
			"//   - The repository notes\n"
			"//   - The list of the repository URL in the form:\n"
			"//       [type, url, description]\n"
			"//   - A list of the sources referencing this repository, in the form:\n"
			"//       - source index (in table 'S')\n"
			"//       - media type\n"
			"//       - call number\n"
			"//       - notes of the repository reference\n"
			"R = [")
		sep = "\n"
		repo_list = list(self.obj_dict[Repository])
		if (not self.inc_repositories): repo_list = []
		repo_list.sort(key = lambda x: self.obj_dict[Repository][x][OBJDICT_INDEX])
		for repo_handle in repo_list:
			repo = self.database.get_repository_from_handle(repo_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Repository][repo_handle][OBJDICT_GID] + "\",")
			name = repo.get_name() or ""
			sw.write("\"" + script_escape(name) + "\",\n")
			type = repo.get_type() or ""
			sw.write("\"" + script_escape(str(type)) + "\",\n")
			# Addresses
			sw.write("[\n" + self._data_addresses(repo) + "\n],\n")
			# Get repository notes
			sw.write("\"" + script_escape(self.get_notes_text(repo)) + "\",\n")
			# Get repository URL
			sw.write(self._data_url_list(repo))
			sw.write(",\n")
			# Get source references
			sw.write(self._data_repo_backref_index(repo, Source))
			sw.write("\n]")
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_repo.js", sw.getvalue())


	def _export_media(self):
		"""
		Export media data in Javascript file
		The media data is stored in the Javascript Array "M"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'M' is sorted by media title\n"
			"// 'M' gives for each media object:\n"
			"//   - Gramps ID\n"
			"//   - The media title\n"
			"//   - The media path in Gramps\n"
			"//   - The media path were the media is really located\n"
			"//   - The media MIME type\n"
			"//   - The media date\n"
			"//   - The media date in ISO format (sortable)\n"
			"//   - The media notes\n"
			"//   - A list of the media source citations index (in table 'C')\n"
			"//   - The list of the media attributes in the form:\n"
			"//       [attribute, value, note, list of citations]\n"
			"//   - Media thumbnail path\n"
			"//   - A list of the person referencing this media (including the person events referencing this media), in the form:\n"
			"//       - person index (in table 'I')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the family referencing this media (including the family events referencing this media), in the form:\n"
			"//       - family index (in table 'F')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the source referencing this media (including the source citations referencing this media), in the form:\n"
			"//       - source index (in table 'S')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"//   - A list of the places referencing this media, in the form:\n"
			"//       - place index (in table 'P')\n"
			"//       - media thumbnail path\n"
			"//       - [x1, y1, x2, y2] of the media reference\n"
			"//       - notes of the media reference\n"
			"//       - list of the media reference source citations index (in table 'C')\n"
			"M = [")
		sep = "\n"
		media_list = list(self.obj_dict[MediaObject])
		if (not self.inc_gallery): media_list = []
		media_list.sort(key = lambda x: self.obj_dict[MediaObject][x][OBJDICT_INDEX])
		for media_handle in media_list:
			media = self.database.get_object_from_handle(media_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[MediaObject][media_handle][OBJDICT_GID] + "\",")
			title = media.get_description() or ""
			sw.write("\"" + script_escape(html_escape(title)) + "\",\n")
			sw.write("\"" + script_escape(media.get_path()) + "\",\n")
			path = self.get_media_web_path(media)
			sw.write("\"" + script_escape(path) + "\",\n")
			sw.write("\"" + script_escape(media.get_mime_type()) + "\",\n")
			# Get media date
			date = format_date(media.get_date_object()) or ""
			sw.write("\"" + date + "\",\n")
			date = format_date(media.get_date_object(), True) or ""
			sw.write("\"" + date + "\",\n")
			# Get media notes
			sw.write("\"" + script_escape(self.get_notes_text(media)) + "\",\n")
			# Get media sources
			sw.write(self._data_source_citation_index(media))
			sw.write(",\n")
			# Get media attributes
			sw.write(self._data_attributes(media))
			sw.write(",\n")
			# Get media thumbnail
			sw.write("\"" + self.copy_thumbnail(media, (0,0,100,100)) + "\",\n")
			# Get media references
			sw.write(self._data_media_backref_index(media, Person))
			sw.write(",\n")
			sw.write(self._data_media_backref_index(media, Family))
			sw.write(",\n")
			sw.write(self._data_media_backref_index(media, Source))
			sw.write(",\n")
			sw.write(self._data_media_backref_index(media, Place))
			sw.write("\n")
			sw.write("]")
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_media.js", sw.getvalue())


	def _export_places(self):
		"""
		Export places data in Javascript file
		The places data is stored in the Javascript Array "P"
		"""
		sw = StringIO()
		sw.write(
			"// This file is generated\n\n"
			"// 'P' is sorted by place name\n"
			"// 'P' gives for each media object:\n"
			"//   - Gramps ID\n"
			"//   - The place name\n"
			"//   - The place locations parts for the main and alternate names, in the form:\n"
			"//       (index 0 is main name, others are for alternate names)\n"
			"//       [street, locality, parish, city, state, county, zip, country]\n"
			"//   - The coordinates [latitude, longitude]\n\n"
			"//   - The place notes\n"
			"//   - A list of the place source citations index (in table 'C')\n"
			"//   - The list of the place URL in the form:\n"
			"//       [type, url, description]\n"
			"//   - A list of the person index (in table 'I') for events referencing this place\n"
			"//     (including the persons directly referencing this place)\n"
			"//   - A list of the family index (in table 'F') for events referencing this place\n"
			"P=[")
		sep = "\n"
		place_list = list(self.obj_dict[Place])
		place_list.sort(key = lambda x: self.obj_dict[Place][x][OBJDICT_INDEX])
		for place_handle in place_list:
			place = self.database.get_place_from_handle(place_handle)
			sw.write(sep)
			sw.write("[\"" + self.obj_dict[Place][place_handle][OBJDICT_GID] + "\",")
			place_name = report_utils.place_name(self.database, place_handle)
			sw.write("\"" + script_escape(place_name) + "\"")
			if (not self.inc_places):
				sw.write("]")
				sep = ",\n"
				continue
			sw.write(",\n")
			locations = []
			if (DWR_VERSION_410):
				ml = get_main_location(self.database, place)
				loc = Location()
				loc.street = ml.get(PlaceType.STREET, '')
				loc.locality = ml.get(PlaceType.LOCALITY, '')
				loc.city = ml.get(PlaceType.CITY, '')
				loc.parish = ml.get(PlaceType.PARISH, '')
				loc.county = ml.get(PlaceType.COUNTY, '')
				loc.state = ml.get(PlaceType.STATE, '')
				loc.postal = place.get_code()
				loc.country = ml.get(PlaceType.COUNTRY, '')
				locations.append(loc)
			else:
				if (place.main_loc):
					ml = place.get_main_location()
					if (ml and not ml.is_empty()): locations.append(ml)
			altloc = place.get_alternate_locations()
			if (altloc):
				altloc = [nonempt for nonempt in altloc if (not nonempt.is_empty())]
				locations += altloc
			loctabs = []
			for loc in locations:
				loctab = [
					loc.street,
					loc.locality,
					loc.city,
					loc.parish,
					loc.county,
					loc.state,
					loc.postal,
					loc.country,
				]
				loctab = [(data or "") for data in loctab]
				loctab = ["\"" + script_escape(data) + "\"" for data in loctab]
				loctabs.append("[" + ",".join(loctab) + "]")
			sw.write("[" + ",".join(loctabs) + "],\n")
			latitude = place.get_latitude()
			longitude = place.get_longitude()
			if (latitude and longitude):
				coords = conv_lat_lon(latitude, longitude, "D.D8")
			else:
				coords = ("", "")
			sw.write("[\"" + "\",\"".join(coords) + "\"]\n,")
			# Get place notes
			sw.write("\"" + script_escape(self.get_notes_text(place)) + "\",\n")
			# Get place media
			sw.write(self._data_media_reference_index(place))
			sw.write(",\n")
			# Get place sources
			sw.write(self._data_source_citation_index(place))
			sw.write(",\n")
			# Get place URL
			sw.write(self._data_url_list(place))
			sw.write(",\n")
			# Get back references
			sw.write(self._data_bkref_index(Place, place_handle, Person))
			sw.write(",\n")
			sw.write(self._data_bkref_index(Place, place_handle, Family))
			sw.write("\n]")
			sep = ",\n"
		sw.write("\n];\n")
		self.update_file("dwr_db_place.js", sw.getvalue())


	def get_notes_text(self, object):
		if (not self.inc_notes): return("")
		notelist = object.get_note_list()
		htmllist = self.dump_notes(notelist)
		if (not htmllist): return("")
		return(html_text(htmllist))


	def get_notes_attributes_text(self, notelist, attrlist):
		if (not self.inc_notes): return("")
		# Get notes
		htmllist = self.dump_notes(notelist)
		# Get attributes
		for attr in attrlist:
			if (not htmllist): htmllist = Html("div")
			htmllist.extend(Html(
				"p", _("%(type)s: %(value)s") % {
				'type': Html("b", attr.get_type()),
				'value': attr.get_value()
				}
			))
			# Also output notes attached to the attributes
			notelist2 = attr.get_note_list()
			htmlnotelist = self.dump_notes(notelist2)
			if (htmlnotelist): htmllist.extend(htmlnotelist)
		if (not htmllist): return("")
		return(html_text(htmllist))


	def dump_notes(self, notelist):
		"""
		dump out of list of notes with very little elements of its own

		@param: notelist -- list of notes
		"""
		notesection = None
		if (not notelist): return(notesection)
		if (not self.inc_notes): return(notesection)
		for note_handle in notelist:
			if (not notesection): notesection = Html("div")
			this_note = self.database.get_note_from_handle(note_handle)
			if this_note is not None:
				if (self.print_notes_type):
					notesection.extend(Html("i", str(this_note.type), class_="NoteType"))
				notesection.extend(self.get_note_format(this_note))
		return(notesection)

	def get_note_format(self, note):
		"""
		will get the note from the database, and will return either the
		styled text or plain note
		"""
		text = ""
		if note is not None:
			# retrieve the body of the note
			note_text = note.get()
			# styled notes
			htmlnotetext = self.styled_note(note.get_styledtext(),
											note.get_format(), contains_html =
											note.get_type() == NoteType.HTML_CODE)
			text = htmlnotetext or Html("p", note_text)
		# return text of the note to its callers
		return(text)

	def styled_note(self, styledtext, format, contains_html=False):
		"""
		styledtext : assumed a StyledText object to write
		format : = 0 : Flowed, = 1 : Preformatted
		style_name : name of the style to use for default presentation
		"""
		text = str(styledtext)

		if (not text): return('')

		s_tags = styledtext.get_tags()
		htmllist = Html("div", class_="grampsstylednote")
		if contains_html:
			markuptext = self._backend.add_markup_from_styled(text,
															  s_tags,
															  split='\n',
															  escape=False)
			htmllist += markuptext
		else:
			markuptext = self._backend.add_markup_from_styled(text,
															  s_tags,
															  split='\n')
			linelist = []
			linenb = 1
			sigcount = 0
			for line in markuptext.split('\n'):
				[line, sigcount] = process_spaces(line, format)
				if sigcount == 0:
					# The rendering of an empty paragraph '<p></p>'
					# is undefined so we use a non-breaking space
					if linenb == 1:
						linelist.append('&nbsp;')
					htmllist.extend(Html('p') + linelist)
					linelist = []
					linenb = 1
				else:
					if linenb > 1:
						linelist[-1] += '<br />'
					linelist.append(line)
					linenb += 1
			if linenb > 1:
				htmllist.extend(Html('p') + linelist)
			# if the last line was blank, then as well as outputting the previous para,
			# which we have just done,
			# we also output a new blank para
			if sigcount == 0:
				linelist = ["&nbsp;"]
				htmllist.extend(Html('p') + linelist)
		return(htmllist)


	def _data_source_citation_index(self, object):
		"""
		Export sources citations indexes related to L{object}
		See L{_data_source_citation_index_from_list}
		"""
		citationlist = object.get_citation_list()
		return(self._data_source_citation_index_from_list(citationlist))

	def _data_source_citation_index_from_list(self, citationlist):
		"""
		List sources citations indexes of the L{citationlist} in a string representing a Javascript Array
		@return: citations indexes as a string representing a Javascript Array
		"""
		if (not self.inc_sources): return("[]")
		if not citationlist: return("[]")
		sep = ""
		txt = "["
		for citation_handle in citationlist:
			if (not txt): txt = Html("div")
			citation = self.database.get_citation_from_handle(citation_handle)
			if (citation is not None and (citation_handle in self.obj_dict[Citation])):
				source_handle = citation.get_reference_handle()
				source = self.database.get_source_from_handle(source_handle)
				if (source is not None and (source_handle in self.obj_dict[Source])):
					title = source.get_title()
					if (not title): title = source.get_gramps_id()
					txt += sep + str(self.obj_dict[Citation][citation_handle][OBJDICT_INDEX])
					sep = ","
		txt += "]"
		return(txt)


	def _data_repo_reference_index(self, object):
		"""
		Build a list of the repositories references index, in the form given by L{_data_repo_ref}
		"""
		if (not self.inc_repositories): return("[]")
		refs = object.get_reporef_list()
		if (not refs): return("[]")
		sep = "\n"
		txt = "["
		for ref in refs:
			repo_handle = ref.get_reference_handle()
			if (repo_handle in self.obj_dict[Repository]):
				txt += sep + "\t" + self._data_repo_ref(ref, self.obj_dict[Repository][repo_handle][OBJDICT_INDEX])
				sep = ",\n"
		txt += "]"
		return(txt)

	def _data_repo_ref(self, ref, index):
		"""
		Build a repository reference, in the form:
		 - repository index (in table 'R')
		 - media type
		 - call number
		 - notes of the repository reference
		"""
		repo_handle = ref.get_reference_handle()
		repo = self.database.get_repository_from_handle(repo_handle)
		txt = "["
		txt += str(index) + ","
		txt += "\"" + script_escape(str(ref.get_media_type())) + "\","
		txt += "\"" + script_escape(ref.get_call_number()) + "\","
		txt += "\"" + script_escape(self.get_notes_text(ref)) + "\""
		txt += "]"
		return(txt)


	def _data_media_reference_index(self, object):
		"""
		Build a list of the media references index, in the form given by L{_data_media_ref}
		"""
		if (not self.inc_gallery): return("[]")
		refs = object.get_media_list()
		if (not refs): return("[]")
		sep = "\n"
		txt = "["
		for ref in refs:
			media_handle = ref.get_reference_handle()
			if (media_handle in self.obj_dict[MediaObject]):
				txt += sep + "\t" + self._data_media_ref(ref, self.obj_dict[MediaObject][media_handle][OBJDICT_INDEX])
				sep = ",\n"
		txt += "]"
		return(txt)

	def _data_media_ref(self, ref, index):
		"""
		Build a media reference, in the form:
		 - media index (in table 'M')
		 - media thumbnail path
		 - [x1, y1, x2, y2] of the media reference
		 - notes of the media reference
		 - list of the media reference source citations index (in table 'C')
		"""
		media_handle = ref.get_reference_handle()
		media = self.database.get_object_from_handle(media_handle)
		txt = "["
		txt += str(index)
		txt += ",\""
		txt += self.copy_thumbnail(media, ref.get_rectangle())
		txt += "\",["
		rect = ref.get_rectangle() or (0,0,100,100)
		txt += ",".join(str(x) for x in rect)
		txt += "],"
		attrlist = ref.get_attribute_list()
		txt += "\"" + script_escape(self.get_notes_attributes_text(ref.get_note_list(), attrlist)) + "\","
		citationlist = ref.get_citation_list()
		for attr in attrlist: citationlist.extend(attr.get_citation_list())
		# BUG: it seems that attribute references are given by both ref.get_citation_list and attr.get_citation_list
		txt += self._data_source_citation_index_from_list(citationlist)
		txt += "]"
		return(txt)


	def get_media_web_path(self, media):
		"""
		Return the path of the media from the web pages
		This function could be called several times for the same media
		This function copies the media to the web pages directories if necessary
		"""
		media_path = media.get_path()
		if (media_path):
			norm_path = media_path_full(self.database, media_path)
			if (os.path.isfile(norm_path)):
				if (self.copy_media):
					ext = os.path.splitext(norm_path)[1]
					iname = str(media.get_handle()) + ext
					iname = iname.lower()
					if (iname not in self.images_copied):
						self.copy_file(norm_path, iname, "image")
						self.images_copied.add(iname)
					web_path = "image/" + iname
				else:
					try:
						web_path = os.path.relpath(norm_path, self.target_path)
						web_path = web_path.replace("\\", "/")
					except:
						web_path = urlparse.urljoin('file:', urllib.pathname2url(norm_path))
						log.warning(_("Impossible to convert \"%(path)s\" to a relative path.") % {"path": norm_path})
				return(web_path)
		log.warning("Warning: File not found \"%(path)s\"" % {"path": str(media_path)})
		return(media_path)


	def copy_thumbnail(self, media, region = None):
		"""
		Given a handle (and optional region) make (if needed) an
		up-to-date cache of a thumbnail, and call copy_file
		to copy the cached thumbnail to the website.
		Return the new path to the image.
		"""
		if (region and region[0] == 0 and region[1] == 0 and region[2] == 100 and region[3] == 100):
			region = None
		handle = media.get_handle()
		tname = handle + (("-%d,%d-%d,%d.png" % region) if region else ".png")
		if (media.get_mime_type()):
			from_path = get_thumbnail_path(
				media_path_full(self.database, media.get_path()),
				media.get_mime_type(),
				region)
			if not os.path.isfile(from_path):
				from_path = os.path.join(IMAGE_DIR, "document.png")
		else:
			from_path = os.path.join(IMAGE_DIR, "document.png")
		if (tname not in self.thumbnail_created):
			self.copy_file(from_path, tname, "thumb")
			self.thumbnail_created.add(tname)
		web_path = "thumb/" + tname
		return(web_path)


	def _data_attributes(self, object):
		"""
		Build the list of the L{object} attributes as a Javascript string, in the form:
		  [attribute, value, note, list of citations]
		"""
		attrlist = object.get_attribute_list()
		txt = "["
		sep = ""
		for attr in attrlist:
			txt += sep + "["
			txt += "\"" + script_escape(str(attr.get_type())) + "\","
			txt += "\"" + script_escape(str(attr.get_value())) + "\","
			# Get attribute notes
			txt += "\"" + script_escape(self.get_notes_text(attr)) + "\","
			# Get attribute sources
			txt += self._data_source_citation_index(attr)
			txt += "]"
			sep = ","
		txt += "]"
		return(txt)

	def _data_attributes_src(self, source):
		"""
		Build the list of the L{source} sources attributes as a Javascript string, in the form:
		  [attribute, value, "", []]
		"""
		attrlist = source.get_attribute_list()
		txt = "["
		sep = ""
		for attr in attrlist:
			txt += sep + "["
			txt += "\"" + script_escape(str(attr.get_type())) + "\","
			txt += "\"" + script_escape(str(attr.get_value())) + "\","
			# There aren't any attribute notes
			txt += "\"\","
			# There aren't any attribute sources
			txt += "[]"
			txt += "]"
			sep = ","
		txt += "]"
		return(txt)

	def _data_url_list(self, object):
		"""
		Build the list of the L{object} URL as a Javascript string, in the form:
		  [type, url, description]
		"""
		urllist = object.get_url_list()
		txt = "["
		sep = ""
		for url in urllist:
			_type = url.get_type()
			uri = url.get_path()
			descr = url.get_description()
			# Email address
			if _type == UrlType.EMAIL:
				if not uri.startswith("mailto:"):
					uri = "mailto:%(email)s" % { 'email' : uri }
			# Web Site address
			elif _type == UrlType.WEB_HOME:
				if not (uri.startswith("http://") or uri.startswith("https://")):
					uri = "http://%(website)s" % { "website" : uri }
			# FTP server address
			elif _type == UrlType.WEB_FTP:
				if not (uri.startswith("ftp://") or uri.startswith("ftps://")):
					uri = "ftp://%(ftpsite)s" % { "ftpsite" : uri }
			txt += sep + "["
			txt += "\"" + str(_type) + "\","
			txt += "\"" + script_escape(uri) + "\","
			txt += "\"" + script_escape(descr) + "\""
			txt += "]"
			sep = ","
		txt += "]"
		return(txt)


	def _export_surnames(self):
		"""
		Export surnames data in Javascript file
		The surnames data is stored in the Javascript Array "SN"
		"""
		# Extract the surnames data
		surnames = defaultdict(list) #: Dictionary giving for each surname: the list of person handles with this surname
		sortnames = {} #: Dictionary giving for each person handle: a sortable string for the person
		person_list = list(self.obj_dict[Person].keys())
		for person_handle in person_list:
			person = self.database.get_person_from_handle(person_handle)
			primary_name = person.get_primary_name()
			if (primary_name.group_as):
				surname = primary_name.group_as
			else:
				surname = self.database.get_name_group_mapping(_nd.primary_surname(primary_name))
			# Treat people who have no name with those whose name is just 'whitespace'
			if (surname is None or surname.isspace()):
				surname = ""
			sortnames[person_handle] = _nd.sort_string(primary_name)
			surnames[surname].append(person_handle)
		# Sort surnames
		surns_keys = list(surnames.keys())
		surns_keys.sort(key = SORT_KEY)
		# Generate the file
		sw1 = StringIO()
		sw1.write(
			"// This file is generated\n\n"
			"// 'SN' is sorted by surname\n"
			"// 'SN' gives for each surname:\n"
			"//  - the surname\n"
			"//  - the surname first letter\n"
			"//  - the list of persion index (in table 'I') with this surname\n"
			"\nSN = [")
		sep = "\n"
		for s in surns_keys:
			# Sort persons
			surnames[s].sort(key = lambda x: sortnames[x])
			tab = ",".join([str(self.obj_dict[Person][x][OBJDICT_INDEX]) for x in surnames[s]])
			sw1.write(sep + "[\"" + script_escape(s) + "\", \"" + first_letter(s).strip() + "\", [" + tab + "]]")
			sep = ",\n"
		sw1.write("\n];\n")
		self.update_file("dwr_db_surns.js", sw1.getvalue())


	def _data_families_index(self, person):
		fams = []
		family_list = person.get_family_handle_list()
		if (family_list):
			fams = [self.obj_dict[Family][family_handle][OBJDICT_INDEX] for family_handle in family_list if (family_handle in self.obj_dict[Family])]
		return(
			"[" +
			",".join([str(i) for i in fams]) +
			"]")

	def _data_partners_index(self, family):
		indis = []
		person_handle = family.get_father_handle()
		if (person_handle and (person_handle in self.obj_dict[Person])):
			indis.append(self.obj_dict[Person][person_handle][OBJDICT_INDEX])
		person_handle = family.get_mother_handle()
		if (person_handle and (person_handle in self.obj_dict[Person])):
			indis.append(self.obj_dict[Person][person_handle][OBJDICT_INDEX])
		return(
			"[" +
			",".join([str(i) for i in indis]) +
			"]")

	def _data_parents_families_index(self, person):
		links = []
		family_list = person.get_parent_family_handle_list()
		if (family_list):
			for family_handle in family_list:
				if (family_handle not in self.obj_dict[Family]): continue
				family = self.database.get_family_from_handle(family_handle)
				child_refs = [
					child_ref
					for child_ref in family.get_child_ref_list()
					if (child_ref.ref == person.get_handle())
				]
				if (len(child_refs) >= 1):
					index = self.obj_dict[Family][family_handle][OBJDICT_INDEX]
					links.append(self._data_child_ref(index, child_refs[0]))
		return("[" + ",".join(links) + "]")

	def _data_children_index(self, family):
		links = [
			self._data_child_ref(self.obj_dict[Person][child_ref.ref][OBJDICT_INDEX], child_ref)
			for child_ref in family.get_child_ref_list()
			if (child_ref.ref in self.obj_dict[Person])
		]
		return("[" + ",".join(links) + "]")

	def _data_child_ref(self, index, child_ref):
		#  Child reference in the form:
		#    [index, relation to father, relation to mother, notes, list of citations]
		txt = "["
		txt += str(index) + ","
		txt += "\"" + script_escape(str(child_ref.get_father_relation())) + "\","
		txt += "\"" + script_escape(str(child_ref.get_mother_relation())) + "\","
		# Get child reference notes
		txt += "\"" + script_escape(self.get_notes_text(child_ref)) + "\","
		# Get child reference sources
		txt += self._data_source_citation_index(child_ref)
		txt += "]"
		return(txt)


	def _data_associations(self, person):
		assoclist = person.get_person_ref_list()
		rels = []
		for person_ref in assoclist:
			txt = "["
			if (person_ref.ref not in self.obj_dict[Person]): continue
			txt += "%i," % self.obj_dict[Person][person_ref.ref][OBJDICT_INDEX]
			txt += "\"" + script_escape(str(person_ref.get_relation())) + "\","
			# Get association notes
			txt += "\"" + script_escape(self.get_notes_text(person_ref)) + "\","
			# Get association sources
			txt += self._data_source_citation_index(person_ref)
			txt += "]"
			rels.append(txt)
		return("[" + ",".join(rels) + "]")


	def get_birth_year(self, person):
		ev = get_birth_or_fallback(self.database, person)
		return(self._get_year_text(ev) or "?")
	def get_death_year(self, person):
		ev = get_death_or_fallback(self.database, person)
		return(self._get_year_text(ev))
	def get_marriage_year(self, family):
		ev = get_marriage_or_fallback(self.database, family)
		return(self._get_year_text(ev))
	def _get_year_text(self, event):
		y = ""
		if (event):
			y = "?"
			date = event.get_date_object()
			mod = date.get_modifier()
			start = date.get_start_date()
			if (mod == Date.MOD_NONE and start != Date.EMPTY):
				y = str(start[2])
				self.min_period = min(self.min_period, start[2])
				self.max_period = max(self.max_period, start[2])
		return(y)

	def get_birth_place(self, person):
		ev = get_birth_or_fallback(self.database, person)
		return(self._get_place_text(ev))
	def get_death_place(self, person):
		ev = get_death_or_fallback(self.database, person)
		return(self._get_place_text(ev))
	def get_marriage_place(self, family):
		ev = get_marriage_or_fallback(self.database, family)
		return(self._get_place_text(ev))
	def _get_place_text(self, event):
		place_name = ""
		if (event):
			place_handle = event.get_place_handle()
			if (place_handle and (place_handle in self.obj_dict[Place])):
				place_name = report_utils.place_name(self.database, place_handle)
		return(place_name)

	def get_death_age(self, person):
		ev_birth = get_birth_or_fallback(self.database, person)
		birth_date = None
		if (ev_birth): birth_date = ev_birth.get_date_object()
		ev_death = get_death_or_fallback(self.database, person)
		death_date = None
		if (ev_death): death_date = ev_death.get_date_object()
		if (birth_date):
			alive = probably_alive(person, self.database, Today())
			if (not alive and death_date):
				nyears = death_date - birth_date
				nyears.format(precision = 3)
				age = int(nyears)
				if (age):
					age = round(abs(age) / 365.25)
					self.min_age = min(self.min_age, age)
					self.max_age = max(self.max_age, age)
				return(str(nyears))
		return("");


	def _export_pages(self):
		"""
		Generate the HTML pages
		"""
		
		# Check pages configuration (in the options)
		pcset = set(self.page_content)
		if (len(pcset) != len(self.page_content)):
			log.error(_("The pages configuration is not valid: several pages have the same content"))
			return
			
		# Export the script containing the web  pages configuration
		self._export_script_configuration()
		
		# List of the scripts and CSS stylesheets used in the HTML pages
		# Note: other scripts and stylesheets are dynamically loaded in "dwr_start.js"
		# "dwr_start.js" is loaded in all pages uncontitionally (see L{write_header})
		dbscripts = ["dwr_db_indi.js", "dwr_db_fam.js", "dwr_db_sour.js", "dwr_db_cita.js", "dwr_db_media.js", "dwr_db_place.js", "dwr_db_repo.js", "dwr_db_surns.js"] #: list of the scripts to embed in the HTML
		mapscripts = [] #: list of the scripts to embed in the HTML pages that show a map
		mapstyles = [] #: list of the CSS stylesheets to embed in the HTML pages that show a map
		if (self.options['placemappages'] or self.options['familymappages']):
			if (self.options['mapservice'] == "Google"):
				mapscripts = ["http://maps.googleapis.com/maps/api/js?sensor=false"]
			else:
				mapscripts = ["http://openlayers.org/en/v3.0.0/build/ol.js"]
				mapstyles = ["http://openlayers.org/en/v3.0.0/css/ol.css"]
				# mapscripts = ["ol.js"]
				# mapstyles = ["ol.css"]
				# mapscripts = ["http://cdn.leafletjs.com/leaflet-0.7.3/leaflet.js"]
				# mapstyles = ["http://cdn.leafletjs.com/leaflet-0.7.3/leaflet.css"]
				
		#: List of page to generate: index in L{PAGES_NAMES}, Javascript code for generating the page
		parts = {
			PAGE_PERSON: (dbscripts, "DwrMain(PAGE_INDI);"),
			PAGE_SURNAMES: (dbscripts, "printSurnamesIndex();"),
			PAGE_PERSON_INDEX: (dbscripts, "printPersonsIndex();"),
			PAGE_FAMILY_INDEX: (dbscripts, "printFamiliesIndex();"),
			PAGE_SOURCE_INDEX: (dbscripts, "printSourcesIndex();"),
			PAGE_MEDIA_INDEX: (dbscripts, "printMediaIndex();"),
			PAGE_PLACE_INDEX: (dbscripts, "printPlacesIndex();"),
			PAGE_ADDRESS_INDEX: (dbscripts, "printAddressesIndex();"),
			PAGE_REPOSITORY_INDEX: (dbscripts, "printReposIndex();"),
			PAGE_SVG_TREE: (dbscripts, "DwrMain(PAGE_SVG_TREE);"),
		}
		
		# Export the HTML pages listed in L{PAGES_NAMES}
		for i in range(self.pages_number):
			pc = self.page_content[i] # Get the page i contents defined in the options
			filename = PAGES_NAMES[pc][2]
			title = self.page_name[pc]
			if (pc in parts):
				# The page is not a custom page
				(scripts, cmd) = parts[pc]
				self._export_html_page(filename, title, cmd, True, scripts)
			else:
				# The page is a custom page
				i_cst = pc - PAGE_CUSTOM
				self._export_custom_page(filename, title, self.custom_menu[i_cst], self.custom_note[i_cst])

		# The person page is required
		if (PAGE_PERSON not in self.page_content):
			self._export_html_page("person.html", self.page_name[PAGE_PERSON], "DwrMain(PAGE_INDI);", True, dbscripts)

		# The search results page is required
		self._export_html_page("search.html", _("Search results"), "DwrMain(PAGE_SEARCH);", True, dbscripts)

		# Page for printing a family (if needed)
		if (self.inc_families):
			self._export_html_page("family.html", self.page_name[PAGE_FAMILY_INDEX], "DwrMain(PAGE_FAM);", True, dbscripts + mapscripts , mapstyles)
		
		# Generate page surnames pages (if surnames page is used)
		if (PAGE_SURNAMES in self.page_content):
			# Page for persons with a given surname
			self._export_html_page("surname.html", self.page_name[PAGE_SURNAMES], "printSurnameIndex();", True, dbscripts)
			# Page for surnames sorted by quantity
			self._export_html_page("surnames2.html", self.page_name[PAGE_SURNAMES], "printSurnamesIndex2();", True, dbscripts)

		# Page for a single family (if needed)
		if (self.inc_sources):
			self._export_html_page("source.html", self.page_name[PAGE_SOURCE_INDEX], "DwrMain(PAGE_SOURCE);", True, dbscripts)

		# Page for a single media (if needed)
		if (self.inc_gallery):
			self._export_html_page("media.html", self.page_name[PAGE_MEDIA_INDEX], "DwrMain(PAGE_MEDIA);", True, dbscripts)

		# Page for a single place (if needed)
		if (self.inc_places):
			self._export_html_page("place.html", self.page_name[PAGE_PLACE_INDEX], "DwrMain(PAGE_PLACE);", True, dbscripts + mapscripts , mapstyles)

		# Page for a single repository (if needed)
		if (self.inc_repositories):
			self._export_html_page("repository.html", self.page_name[PAGE_REPOSITORY_INDEX], "DwrMain(PAGE_REPO);", True, dbscripts)

		# Page for full-screen SVG graph (if SVG graph is used)
		if (PAGE_SVG_TREE in self.page_content):
			self._export_html_page("tree_svg_full.html", self.page_name[PAGE_SVG_TREE], "DwrMain(PAGE_SVG_TREE_FULL);", False, dbscripts)
			self._export_html_page("tree_svg_conf.html", self.page_name[PAGE_SVG_TREE], "DwrMain(PAGE_SVG_TREE_CONF);", True, dbscripts)
			self._export_html_page("tree_svg_save.html", self.page_name[PAGE_SVG_TREE], "DwrMain(PAGE_SVG_TREE_SAVE);", True, dbscripts)


	def _export_script_configuration(self):
		"""
		Generate "dwr_conf.js", which contains:
		 - The pages configuration (mostly extract of the report options),
		 - The localization (translated strings)
		 - Gramps constants that could be used in the Javascript
		"""
		sw = StringIO()
		sw.write("// This file is generated\n\n")
		sw.write("NB_GENERATIONS_MAX = %i;\n" % int(self.options["graphgens"]))
		sw.write("PAGES_TITLE = [")
		sw.write(", ".join([
			("\"" + script_escape(self.page_name[self.page_content[i]]).replace(" ", "&nbsp;") + "\"")
			for i in range(self.pages_number)]))
		sw.write("];\n")
		sw.write("PAGES_FILE = [")
		sw.write(", ".join([
			("\"" + script_escape(PAGES_NAMES[self.page_content[i]][2]) + "\"")
			for i in range(self.pages_number)]))
		sw.write("];\n")
		sw.write("SVG_TREE_TYPES_NAMES = [")
		sw.write(", ".join([("\"" + script_escape(n) + "\"") for n in SVG_TREE_TYPES]))
		sw.write("];\n")
		sw.write("SVG_TREE_SHAPES_NAMES = [")
		sw.write(", ".join([("\"" + script_escape(n) + "\"") for n in SVG_TREE_SHAPES]))
		sw.write("];\n")
		sw.write("SVG_TREE_DISTRIB_ASC_NAMES = [")
		sw.write(", ".join([("\"" + script_escape(n) + "\"") for n in SVG_TREE_DISTRIB_ASC]))
		sw.write("];\n")
		sw.write("SVG_TREE_DISTRIB_DSC_NAMES = [")
		sw.write(", ".join([("\"" + script_escape(n) + "\"") for n in SVG_TREE_DISTRIB_DSC]))
		sw.write("];\n")
		sw.write("SVG_TREE_BACKGROUND_NAMES = [")
		sw.write(", ".join([("\"" + script_escape(n) + "\"") for n in SVG_TREE_BACKGROUNDS]))
		sw.write("];\n")
		sw.write("SVG_TREE_TYPE = %s;\n" % self.options['svg_tree_type'])
		sw.write("SVG_TREE_SHAPE = %s;\n" % self.options['svg_tree_shape'])
		sw.write("SVG_TREE_DISTRIB_ASC = %s;\n" % self.options['svg_tree_distrib_asc'])
		sw.write("SVG_TREE_DISTRIB_DSC = %s;\n" % self.options['svg_tree_distrib_dsc'])
		sw.write("SVG_TREE_BACKGROUND = %s;\n" % self.options['svg_tree_background'])
		sw.write("SVG_TREE_COLOR1 = \"%s\";\n" % self.options['svg_tree_color1'])
		sw.write("SVG_TREE_COLOR2 = \"%s\";\n" % self.options['svg_tree_color2'])
		sw.write("SVG_TREE_SHOW_DUP = " + ("true" if (self.options['svg_tree_dup']) else "false") + ";\n")
		sw.write("SVG_TREE_COLOR_DUP = \"%s\";\n" % self.options['svg_tree_color_dup'])
		sw.write("GRAMPS_PREFERENCES = [];\n")
		for pref in [
			'bordercolor-gender-female-alive',
			'bordercolor-gender-female-death',
			'bordercolor-gender-male-alive',
			'bordercolor-gender-male-death',
			'bordercolor-gender-unknown-alive',
			'bordercolor-gender-unknown-death',
			'color-gender-female-alive',
			'color-gender-female-death',
			'color-gender-male-alive',
			'color-gender-male-death',
			'color-gender-unknown-alive',
			'color-gender-unknown-death',
			]:
			sw.write("GRAMPS_PREFERENCES['%s'] = \"%s\";\n" % (pref, config.get('preferences.%s' % pref)))
		self.compute_background_colors();
		sw.write("SVG_BACKGROUND_GEN_COLORS = [" + ", ".join(
			[("\"#%02x%02x%02x\"" % (r, g, b)) for (r, g, b) in self.background_gen_colors])
			+ "];\n")
		sw.write("SVG_BACKGROUND_GRAD_COLORS = [" + ", ".join(
			[("\"#%02x%02x%02x\"" % (r, g, b)) for (r, g, b) in self.background_grad_colors])
			+ "];\n")
		sw.write("MIN_AGE = %i;\n" % self.min_age)
		sw.write("MAX_AGE = %i;\n" % self.max_age)
		sw.write("MIN_PERIOD = %i;\n" % self.min_period)
		sw.write("MAX_PERIOD = %i;\n" % self.max_period)
		sw.write("SVG_TREE_COLOR_SCHEME0 = [" + ", ".join(
			[("\"#%02x%02x%02x\"" % (r, g, b)) for (r, g, b) in GENCOLOR[BACKGROUND_WHITE]])
			+ "];\n")
		sw.write("SVG_TREE_COLOR_SCHEME1 = [" + ", ".join(
			[("\"#%02x%02x%02x\"" % (r, g, b)) for (r, g, b) in GENCOLOR[BACKGROUND_SCHEME1]])
			+ "];\n")
		sw.write("SVG_TREE_COLOR_SCHEME2 = [" + ", ".join(
			[("\"#%02x%02x%02x\"" % (r, g, b)) for (r, g, b) in GENCOLOR[BACKGROUND_SCHEME2]])
			+ "];\n")
		sw.write("SVG_GENDER_K = 0.9;\n")
		sw.write("FOOTER=\"" + script_escape(self.get_header_footer_notes("footernote")) + "\";\n")
		sw.write("HEADER=\"" + script_escape(self.get_header_footer_notes("headernote")) + "\";\n")
		sw.write("COPYRIGHT=\"" + script_escape(self.get_copyright_license()) + "\";\n")
		sw.write("INDEX_SHOW_BIRTH=" + ("true" if (self.options['showbirth']) else "false") + ";\n")
		sw.write("INDEX_SHOW_DEATH=" + ("true" if (self.options['showdeath']) else "false") + ";\n")
		sw.write("INDEX_SHOW_MARRIAGE=" + ("true" if (self.options['showmarriage']) else "false") + ";\n")
		sw.write("INDEX_SHOW_PARTNER=" + ("true" if (self.options['showpartner']) else "false") + ";\n")
		sw.write("INDEX_SHOW_PARENTS=" + ("true" if (self.options['showparents']) else "false") + ";\n")
		sw.write("INDEX_SHOW_ALL_SIBLINGS=" + ("true" if (self.options['birthorder']) else "false") + ";\n")
		sw.write("INDEX_SHOW_BKREF_TYPE=" + ("true" if (self.options['bkref_type']) else "false") + ";\n")
		sw.write("SORT_CHILDREN=" + ("true" if (self.options['showallsiblings']) else "false") + ";\n")
		sw.write("INC_EVENTS=" + ("true" if (self.inc_events) else "false") + ";\n")
		sw.write("INC_FAMILIES=" + ("true" if (self.inc_families) else "false") + ";\n")
		sw.write("INC_SOURCES=" + ("true" if (self.inc_sources) else "false") + ";\n")
		sw.write("INC_MEDIA=" + ("true" if (self.inc_gallery) else "false") + ";\n")
		sw.write("INC_PLACES=" + ("true" if (self.inc_places) else "false") + ";\n")
		sw.write("INC_REPOSITORIES=" + ("true" if (self.inc_repositories) else "false") + ";\n")
		sw.write("INC_NOTES=" + ("true" if (self.inc_notes) else "false") + ";\n")
		sw.write("INC_ADDRESSES=" + ("true" if (self.inc_addresses) else "false") + ";\n")
		sw.write("MAP_PLACE=" + ("true" if (self.options['placemappages']) else "false") + ";\n")
		sw.write("MAP_FAMILY=" + ("true" if (self.options['familymappages']) else "false") + ";\n")
		sw.write("MAP_SERVICE=\"" + script_escape(self.options['mapservice']) + "\";\n")
		sw.write("__ = {")
		sep = "\n"
		for (s, translated) in (
			("(filtered from _MAX_ total entries)", _("(filtered from _MAX_ total entries)")),
			("(sort by name)", _("(sort by name)")),
			("(sort by quantity)", _("(sort by quantity)")),
			(": activate to sort column ascending", _(": activate to sort column ascending")),
			(": activate to sort column descending", _(": activate to sort column descending")),
			("<p>Click on a person to center the graph on this person.<br>When clicking on the center person, the person page is shown.<p>The type of graph could be selected in the list (on the top left side of the graph)<p>The number of ascending end descending generations could also be adjusted.<p>Use the mouse wheel or the buttons to zoom in and out.<p>The graph could also be shown full-screen.", _("<p>Click on a person to center the graph on this person.<br>When clicking on the center person, the person page is shown.<p>The type of graph could be selected in the list (on the top left side of the graph)<p>The number of ascending end descending generations could also be adjusted.<p>Use the mouse wheel or the buttons to zoom in and out.<p>The graph could also be shown full-screen.")),
			("<p>This page provides the SVG raw code.<br>Copy the contents into a text editor and save as an SVG file.<br>Make sure that the text editor encoding is UTF-8.</p>", _("<p>This page provides the SVG raw code.<br>Copy the contents into a text editor and save as an SVG file.<br>Make sure that the text editor encoding is UTF-8.</p>")),
			("Address", _("Address")),
			("Addresses", _("Addresses")),
			("Age at Death", _("Age at Death")),
			("Alternate Name", _("Alternate Name")),
			("Ancestors", _("Ancestors")),
			("Associations", _("Associations")),
			("Attribute", _("Attribute")),
			("Attributes", _("Attributes")),
			("Background", _("Background")),
			("Birth", _("Birth")),
			("Call Name", _("Call Name")),
			("Call Number", _("Call Number")),
			("Children", _("Children")),
			("Church Parish", _("Church Parish")),
			("Citation", _("Citation")),
			("Citations", _("Citations")),
			("City", _("City")),
			("Click on the map to show it full-screen", _("Click on the map to show it full-screen")),
			("Configuration", _("Configuration")),
			("Country", _("Country")),
			("County", _("County")),
			("Date", _("Date")),
			("Death", _("Death")),
			("Descendants", _("Descendants")),
			("Description", _("Description")),
			("Event", _("Event")),
			("Events", _("Events")),
			("Expand", _("Expand")),
			("Families Index", _("Families Index")),
			("Family Nick Name", _("Family Nick Name")),
			("Father", _("Father")),
			("Female", _("Female")),
			("File ready", _("File ready")),
			("Gender", _("Gender")),
			("Graph help", _("Graph help")),
			("Latitude", _("Latitude")),
			("Link", _("Link")),
			("Loading...", _("Loading...")),
			("Locality", _("Locality")),
			("Location", _("Location")),
			("Longitude", _("Longitude")),
			("Male", _("Male")),
			("Map", _("Map")),
			("Marriage", _("Marriage")),
			("Maximize", _("Maximize")),
			("Media found:", _("Media found:")),
			("Media Index", _("Media Index")),
			("Media Type", _("Media Type")),
			("Media", _("Media")),
			("Mother", _("Mother")),
			("Name", _("Name")),
			("Nick Name", _("Nick Name")),
			("No data available in table", _("No data available in table")),
			("No matching records found", _("No matching records found")),
			("No matching surname.", _("No matching surname.")),
			("None.", _("None.")),
			("Notes", _("Notes")),
			("OK", _("OK")),
			("Parents", _("Parents")),
			("Path", _("Path")),
			("Person page", _("Person page")),
			("Person to search for", _("Person to search for")),
			("Person", _("Person")),
			("Persons found:", _("Persons found:")),
			("Persons Index", _("Persons Index")),
			("Phone", _("Phone")),
			("Place", _("Place")),
			("Places found:", _("Places found:")),
			("Places Index", _("Places Index")),
			("Postal Code", _("Postal Code")),
			("Preparing file ...", _("Preparing file ...")),
			("Processing...", _("Processing...")),
			("References", _("References")),
			("Relationship to Father", _("Relationship to Father")),
			("Relationship to Mother", _("Relationship to Mother")),
			("Relationship", _("Relationship")),
			("Repositories", _("Repositories")),
			("Repository", _("Repository")),
			("Restore", _("Restore")),
			("Save tree as file", _("Save tree as file")),
			("Search:", _("Search:")),
			("Select the background color scheme", _("Select the background color scheme")),
			("Select the children distribution (fan charts only)", _("Select the children distribution (fan charts only)")),
			("Select the number of ascending generations", _("Select the number of ascending generations")),
			("Select the number of descending generations", _("Select the number of descending generations")),
			("Select the parents distribution (fan charts only)", _("Select the parents distribution (fan charts only)")),
			("Select the shape of graph", _("Select the shape of graph")),
			("Select the type of graph", _("Select the type of graph")),
			("Several matches.<br>Precise your search or choose in the lists below.", _("Several matches.<br>Precise your search or choose in the lists below.")),
			("Show _MENU_ entries", _("Show _MENU_ entries")),
			("Showing 0 to 0 of 0 entries", _("Showing 0 to 0 of 0 entries")),
			("Showing _START_ to _END_ of _TOTAL_ entries", _("Showing _START_ to _END_ of _TOTAL_ entries")),
			("Siblings", _("Siblings")),
			("Source", _("Source")),
			("Sources found:", _("Sources found:")),
			("Sources Index", _("Sources Index")),
			("Sources", _("Sources")),
			("Spouses", _("Spouses")),
			("State/ Province", _("State/ Province")),
			("Street", _("Street")),
			("Surnames Index", _("Surnames Index")),
			("SVG tree children distribution", _("SVG tree children distribution")),
			("SVG tree graph shape", _("SVG tree graph shape")),
			("SVG tree graph type", _("SVG tree graph type")),
			("SVG tree parents distribution", _("SVG tree parents distribution")),
			("There is no matching name.", _("There is no matching name.")),
			("Title", _("Title")),
			("Type", _("Type")),
			("Unknown", _("Unknown")),
			("Use the search box above in order to find a person.<br>Women are listed with their maiden name.", _("Use the search box above in order to find a person.<br>Women are listed with their maiden name.")),
			("Used for family", _("Used for family")),
			("Used for media", _("Used for media")),
			("Used for person", _("Used for person")),
			("Used for place", _("Used for place")),
			("Used for source", _("Used for source")),
			("Value", _("Value")),
			("Web Link", _("Web Link")),
			("Web Links", _("Web Links")),
			("Without surname", _("Without surname")),
			("Zoom in", _("Zoom in")),
			("Zoom out", _("Zoom out")),
			):
			sw.write(sep + "\"" + script_escape(s) + "\": \"" + script_escape(translated) + "\"")
			sep = ",\n"
		sw.write("\n};\n")
		sw.write(
			("URLTYPE_UNKNOWN = %i;\n" % UrlType.UNKNOWN) +
			("URLTYPE_CUSTOM = %i;\n" % UrlType.CUSTOM) +
			("URLTYPE_EMAIL = %i;\n" % UrlType.EMAIL) +
			("URLTYPE_WEB_HOME = %i;\n" % UrlType.WEB_HOME) +
			("URLTYPE_WEB_SEARCH = %i;\n" % UrlType.WEB_SEARCH) +
			("URLTYPE_WEB_FTP = %i;\n" % UrlType.WEB_FTP))
		self.update_file("dwr_conf.js", sw.getvalue(), "UTF-8")


	def compute_background_colors(self):
		"""
		Method that is called to precomputed values needed for the background of the boxes
		"""
		maxgen = int(self.options["graphgens"])
		cstart = hex_to_rgb(self.options['svg_tree_color1'])
		cend = hex_to_rgb(self.options['svg_tree_color2'])
		self.cstart_hsv = colorsys.rgb_to_hsv(cstart[0]/255, cstart[1]/255, cstart[2]/255)
		self.cend_hsv = colorsys.rgb_to_hsv(cend[0]/255, cend[1]/255, cend[2]/255)
		# BACKGROUND_GRAD_GEN
		divs = [x / (maxgen-1) for x in range(maxgen)] if (maxgen > 1) else [0]
		rgb_colors = [colorsys.hsv_to_rgb(
			(1-x) * self.cstart_hsv[0] + x * self.cend_hsv[0], 
			(1-x) * self.cstart_hsv[1] + x * self.cend_hsv[1],
			(1-x) * self.cstart_hsv[2] + x * self.cend_hsv[2],
			) for x in divs]
		self.background_gen_colors = [(255*r, 255*g, 255*b) for r, g, b in rgb_colors]
		# BACKGROUND_GRAD_PERIOD, BACKGROUND_GRAD_AGE
		if (self.max_age <= self.min_age):
			self.min_age = 0
			self.max_age = config.get('behavior.max-age-prob-alive')
		self.max_age = min(self.max_age, config.get('behavior.max-age-prob-alive'))
		if (self.max_period < self.min_period):
			self.max_period = self.min_period = Today().get_year()
		steps = 2 * GRADIENTSCALE - 1
		divs = [x/(steps-1) for x in range(steps)]
		rgb_colors = [colorsys.hsv_to_rgb(
			(1-x) * self.cstart_hsv[0] + x * self.cend_hsv[0], 
			(1-x) * self.cstart_hsv[1] + x * self.cend_hsv[1],
			(1-x) * self.cstart_hsv[2] + x * self.cend_hsv[2],
			) for x in divs]
		self.background_grad_colors = [(255*r, 255*g, 255*b) for r, g, b in rgb_colors]
			
			
	def _export_html_page(self, filename, title, cmd, menu, scripts = [], styles = []):
		"""
		Generate an HTML page
		@param filename: output HTML file name
		@param title: Title of the page (prepended to L{self.title}
		@param cmd: Javascript code that generates the page
		@param menu: Whether to put a menu on the page
		@param scripts: Scripts embedded in the page
		@param styles: CSS stylesheets embedded in the page
		"""
		(page, head, body) = self.write_header(title, menu)
		for style in styles:
			head += Html("link", rel = "stylesheet", href = style, type = "text/css")
		for script in scripts:
			head += Html("script", language = "javascript", src = script, charset = self.encoding)
		body += Html("script", cmd, language = "javascript")
		self.update_file(filename, html_text(page))


	def _export_custom_page(self, filename, title, menu, note):
		"""
		Generate an HTML custom page
		@param filename: output HTML file name
		@param title: Title of the page (prepended to L{self.title}
		@param menu: Whether to put a menu on the page
		@param note: note that contains the page contents
		"""
		(page, head, body) = self.write_header(title, menu)
		if (note):
			html = self.get_note_format(self.database.get_note_from_gramps_id(note))
			body += self.replace_note_fields(html)
		self.update_file(filename, html_text(page))


	def write_header(self, title, menu):
		"""
		Generate an HTML page header
		@param title: Title of the page (prepended to L{self.title}
		@param menu: Whether to put a menu on the page
		@return: List of L{Html} objects as follows: (page, head, body)
		"""
		"""
		Note. 'title' is used as currentsection in the navigation links and
		as part of the header title.
		"""
		# Begin each html page...
		xmllang = xml_lang()
		(page, head, body) = Html.page('%s - %s' % (
				html_escape(title),
				html_escape(self.title.strip()),
			),
			self.encoding, xmllang)
		# Header constants
		head += Html("meta", attr = 'name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=1"')
		head += Html("meta", attr = 'name="apple-mobile-web-app-capable" content="yes"')
		head += Html("meta", attr = 'name="generator" content="%s %s %s"' % (PROGRAM_NAME, VERSION, URL_HOMEPAGE))
		head += Html("meta", attr = 'name="author" content="%s"' % self.author)
		# Create script and favicon links
		head += Html("link", type = "image/x-icon", href = "data/favicon.ico", rel = "shortcut icon")
		head += Html("script", language = 'javascript', src = 'data/dwr_start.js')
		# Disable menu
		if (not menu):
			body.attr = "class='dwr-menuless'"
		return(page, head, body)


	def get_header_footer_notes(self, item):
		"""
		Give the header/footer note converted to an HTML string
		@param item: Option giving the note. See options "footernote" and "headernote"
		@return: text of the note
		@rtype: L{String}
		"""
		note = self.options[item]
		if (note):
			html = self.get_note_format(self.database.get_note_from_gramps_id(note))
			return(self.replace_note_fields(html))
		return("")


	def replace_note_fields(self, html):
		"""
		Modify the notes for HTML pages generation
		This allow to add special features or computed data in the pages
		@param html: Note converted to HTML string
		@return: Modified string
		"""
		text = html_text(html)
		# __SEARCH_FORM__ is replaced by a search form
		text = text.replace("__SEARCH_FORM__",
			"<script language='javascript'>\n"
			"<!--\n"
			"embedSearch();\n"
			"//-->\n"
			"</script>\n")
		# __NB_INDIVIDUALS__ is replaced by the number of persons
		# __NB_FAMILIES__ is replaced by the number of families
		# __NB_MEDIA__ is replaced by the number of media objects
		# __NB_SOURCES__ is replaced by the number of sources
		# __NB_REPOSITORIES__ is replaced by the number of repositories
		# __NB_PLACES__ is replaced by the number of places
		text = text.replace("__NB_INDIVIDUALS__", str(len(self.obj_dict[Person])))
		text = text.replace("__NB_FAMILIES__", str(len(self.obj_dict[Family])))
		text = text.replace("__NB_MEDIA__", str(len(self.obj_dict[MediaObject])))
		text = text.replace("__NB_SOURCES__", str(len(self.obj_dict[Source])))
		text = text.replace("__NB_REPOSITORIES__", str(len(self.obj_dict[Repository])))
		text = text.replace("__NB_PLACES__", str(len(self.obj_dict[Place])))
		# __MEDIA_<gid>__ is replaced by the media with gramps ID <gid>
		# __THUMB_<gid>__ is replaced by the thumbnail of the media with gramps ID <gid>
		text2 = text
		for mo in re.finditer(r"__(MEDIA|THUMB)_(.*?)__", text):
			gid = mo.group(2)
			media = self.database.get_object_from_gramps_id(gid)
			if (not media): continue
			tm = mo.group(1)
			if (tm == "THUMB"):
				path = self.copy_thumbnail(media)
				text2 = (
					text2[ : -(len(text) - mo.start(0))] +
					"<img id='" + mo.group(0) + "' class='note_thumb' src='" + path + "'>" +
					text2[-(len(text) - mo.end(0)) : ])
			else:
				path = self.get_media_web_path(media)
				text2 =  (
					text2[ : -(len(text) - mo.start(0))] +
					"<img id='" + mo.group(0) + "' class='note_media' src='" + path + "'>" +
					text2[-(len(text) - mo.end(0)) : ])
		text = text2
		# __EXPORT_DATE__ is replaced by the current date
		# __GRAMPS_VERSION__ is replaced by the Gramps version
		# __GRAMPS_HOMEPAGE__ is replaced by the Gramps homepage
		text = text.replace("__EXPORT_DATE__", format_date(Today()))
		text = text.replace("__GRAMPS_VERSION__", VERSION)
		text = text.replace("__GRAMPS_HOMEPAGE__", "<a href='" + URL_HOMEPAGE + "' class='gramps_homepage'>Gramps</a>")
		# Relative URL are managed
		text = text.replace("relative://relative.", "")
		# __HOME_PERSON_NAME__ is replaced by the home person name
		# __HOME_PERSON_URL__ is replaced by the home person page URL
		# center_person = self.database.get_person_from_gramps_id(self.options['pid'])
		# if (center_person and (center_person.handle in self.obj_dict[Person])):
			# person_name = self.get_name(center_person)
			# person_url = "person.html?idx=%i" % self.obj_dict[Person][center_person.handle][OBJDICT_INDEX]
			# text = text.replace("__HOME_PERSON_NAME__", person_name)
			# text = text.replace("__HOME_PERSON_URL__", person_url)
		return(text)

		
	def get_copyright_license(self):
		"""
		will return either the text or image of the copyright license
		"""
		text = ""
		if (self.copyright == 0):
			if self.author:
				year = Today().get_year()
				text = "<p class='copyright'>&copy; %(year)d %(person)s</p>" % {
					'person' : self.author,
					'year' : year}
		elif (0 < self.copyright < len(_CC)):
			url = "data/somerights20.gif"
			text = "<p class='copyright'>" + _CC[self.copyright] % {'gif_fname' : url} + "</p>"
		# return text or image to its callers
		return(text)


	def update_file(self, fout, txt, encoding = None):
		"""
		Write a string in a file.
		The file is not overwritten if the file exists and already contains the string 
		@param fout: output file name
		@param txt: file contents
		@param encoding: encoding as passed to Python function codecs.open 
		"""
		if (encoding is None): encoding = self.encoding
		f = os.path.join(self.target_path, fout)
		self.created_files.append(f)
		if (os.path.exists(f)):
			try:
				fr = codecs.open(f, "r", encoding = encoding, errors="xmlcharrefreplace")
				txtr = fr.read()
				fr.close()
				if (txtr == txt):
					log.info("File \"%s\" not overwritten (identical)" % fout)
					return
			except:
				pass
		fw = codecs.open(f, "w", encoding = encoding, errors="xmlcharrefreplace")
		fw.write(txt)
		fw.close()
		log.info("File \"%s\" generated" % fout)

	def copy_file(self, from_fname, to_fname, to_dir=""):
		"""
		Copy a file from a source to a (report) destination.
		If to_dir is not present and if the target is not an archive,
		then the destination directory will be created.

		Normally 'to_fname' will be just a filename, without directory path.

		'to_dir' is the relative path name in the destination root. It will
		be prepended before 'to_fname'.
		
		The file is not copied if the contents of 'from_fname' 'to_fname' are identical
		"""
		# log.debug("copying '%s' to '%s/%s'" % (from_fname, to_dir, to_fname))
		dest = os.path.join(self.target_path, to_dir, to_fname)
		destdir = os.path.dirname(dest)
		if not os.path.isdir(destdir):
			os.makedirs(destdir)

		if from_fname != dest:
			try:
				dest_temp = dest + ".temp"
				shutil.copyfile(from_fname, dest_temp)
				self.created_files.append(dest)
				if (os.path.exists(dest)):
					fr = codecs.open(dest, "rb")
					old_bytes = fr.read()
					fr.close()
					fr = codecs.open(dest_temp, "rb")
					new_bytes = fr.read()
					fr.close()
					if (old_bytes == new_bytes):
						os.remove(dest_temp)
						log.info("File \"%s\" not overwritten (identical)" % dest)
						return
					os.remove(dest)
				os.rename(dest_temp, dest)
				log.info("File \"%s\" generated" % dest)
			except:
				log.warning(_("Copying error: %(error)s") % {"error": sys.exc_info()[1]})
				log.error(_("Impossible to copy \"%(src)s\" to \"%(dst)s\"") % {"src": from_fname, "dst": to_fname})
		elif self.warn_dir:
			self.user.warn(
				_("Possible destination error") + "\n" +
				_("You appear to have set your target directory "
				  "to a directory used for data storage. This "
				  "could create problems with file management. "
				  "It is recommended that you consider using "
				  "a different directory to store your generated "
				  "web pages."))
			self.warn_dir = False



	def copy_template_files(self):
		"""
		Copy the template files to the target directory
		
		The template files are:
		 - The files contained in the chosen template directory,
		 - The files contained in the default template directory, unless they are also present in the chosen template directory
		"""
		# Get template path
		tmpl_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "templates", WEB_TEMPLATE_LIST[self.template][0])
		default_tmpl_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "templates", WEB_TEMPLATE_LIST[0][0])
		try:
			# Copy template files
			self.copy_template_files_sub(tmpl_path)
			# Copy default template files if not already copied
			self.copy_template_files_sub(default_tmpl_path)
		except:
			log.error(_("Unable to copy web site template files from \"%(path)s\"") % {"path": tmpl_path})
			raise
			
	def copy_template_files_sub(self, tmpl_path):
		"""
		Copy the template files from L{tmpl_path} to the target directory
		The files already present in the target directory are not overwritten
		@param tmpl_path: template directory, as listed in L{WEB_TEMPLATE_LIST}
		"""
		for (root, dirnames, files) in os.walk(tmpl_path):
			dst_path = root.replace(tmpl_path, self.target_path, 1)
			# Create sub-directories
			for dirname in dirnames:
				# Remove files that have the same name as directories
				dstdirname = os.path.join(dst_path, dirname)
				if (os.path.isfile(dstdirname) or os.path.islink(dstdirname)):
					os.remove(dstdirname)
				# Create directory if needed
				if (not os.path.isdir(dstdirname)):
					os.mkdir(dstdirname)
			# Copy files
			for file in files:
				src = os.path.join(root, file)
				dst = os.path.join(dst_path, file)
				if (dst in self.created_files):
					# File was already copied
					continue
				if (os.path.isfile(dst)):
					# If file already exists, check dates
					stat_src = os.stat(src)
					stat_dst = os.stat(dst)
					# If target file is newer, do not overwrite => If target file is older, delete it
					if (stat_src.st_mtime >= stat_dst.st_mtime):
						os.remove(dst)
					else:
						log.info(_("Keeping \"%(dst)s\" (newer than \"%(src)s\")") % {'src': src, 'dst': dst})
				if (not os.path.exists(dst)):
					shutil.copyfile(src, dst)
					log.info(_("Copying \"%(src)s\" to \"%(dst)s\"") % {'src': src, 'dst': dst})
				self.created_files.append(dst)


	def create_archive(self):
		"""
		Create an archive of the whole web site
		"""
		if (not self.options['archive']): return
		
		# Get archive path and type
		arch_path = self.options['archive_file']
		ext = os.path.splitext(arch_path)[1].lower()
		if (ext not in [".zip", ".tgz"]):
			arch_path += ".zip"
			ext = ".zip"
		
		if (os.path.isdir(arch_path)):
			log.error(_('Invalid file name'))
			log.error(_('The archive file must be a file, not a directory'))
			return
			
		# Get base path for the files inside the archive
		basepath = os.path.splitext(os.path.basename(arch_path))[0]
		
		if (ext == ".zip"):
			try:
				fzip = zipfile.ZipFile(arch_path, "w", zipfile.ZIP_DEFLATED, True)
			except:
				log.error(_("Unable to overwrite archive file \"%(path)s\"") % {"path": arch_path})
				raise
			for file in self.created_files:
				arc_rel_path = file.replace(self.target_path, basepath, 1)
				if (sys.version_info[0] < 3):
					file = file.encode("cp437")
					arc_rel_path = arc_rel_path.encode("cp437")
				try:
					fzip.write(file, arc_rel_path)
				except:
					log.error(_("Unable to add file \"%(file)s\" to archive \"%(archive)s\"") % {"file": file, "archive": arch_path})
					raise
			fzip.close()

		if (ext == ".tgz"):
			try:
				tgz = tarfile.open(arch_path, "w:gz")
			except:
				log.error(_("Unable to overwrite archive file \"%(path)s\"") % {"path": arch_path})
				raise
			for file in self.created_files:
				arc_rel_path = file.replace(self.target_path, basepath, 1)
				try:
					tgz.add(file, arc_rel_path)
				except:
					log.error(_("Unable to add file \"%(file)s\" to archive \"%(archive)s\"") % {"file": path, "archive": arch_path})
					raise
			tgz.close()


	def build_link(self, prop, handle, obj_class):
		"""
		Build a link to an item.
		
		This function is used when converting a Gramps note with hyperlinks into an HTML string
		"""
		if prop == "gramps_id":
			if obj_class in self.database.get_table_names():
				obj = self.database.get_table_metadata(obj_class)["gramps_id_func"](handle)
				if obj:
					handle = obj.get_handle()
				else:
					raise AttributeError("gramps_id '%s' not found in '%s'" % handle, obj_class)
			else:
				raise AttributeError("invalid gramps_id lookup in table name '%s'" % obj_class)
		href = "search.html"
		i = -1
		if (obj_class == "Person"):
			href = "person.html"
			if (handle in self.obj_dict[Person]):
				href = "%s?idx=%i" % (href, self.obj_dict[Person][handle][OBJDICT_INDEX])
		elif (obj_class == "Family"):
			href = "family.html"
			if (handle in self.obj_dict[Family]):
				href = "%s?fdx=%i" % (href, self.obj_dict[Family][handle][OBJDICT_INDEX])
		elif (obj_class == "Source"):
			href = "source.html"
			if (handle in self.obj_dict[Source]):
				href = "%s?sdx=%i" % (href, self.obj_dict[Source][handle][OBJDICT_INDEX])
		elif (obj_class == "Citation"):
			href = "source.html"
			source_handle = self.database.get_citation_from_handle(handle).get_reference_handle()
			if (source_handle in self.obj_dict[Source]):
				href = "%s?sdx=%i" % (href, self.obj_dict[Source][source_handle][OBJDICT_INDEX])
		elif (obj_class == "Repository"):
			href = "repository.html"
			if (handle in self.obj_dict[Repository]):
				href = "%s?rdx=%i" % (href, self.obj_dict[Repository][handle][OBJDICT_INDEX])
		elif (obj_class == "Media"):
			href = "media.html"
			if (handle in self.obj_dict[MediaObject]):
				href = "%s?mdx=%i" % (href, self.obj_dict[MediaObject][handle][OBJDICT_INDEX])
		elif (obj_class == "Place"):
			href = "place.html"
			if (handle in self.obj_dict[Place]):
				href = "%s?pdx=%i" % (href, self.obj_dict[Place][handle][OBJDICT_INDEX])
		else:
			print(_("DynamicWebReport ignoring link type '%(class)s'") % {"class": obj_class})
		return(href)


	def _data_bkref_index(self, obj_class, obj_handle, ref_class):
		"""
		Build a list of object indexes referencing a given object
		@param obj_class: Referenced object class
		@param obj_handle: Referenced object handle
		@param ref_class: Class of the refencing objects
		@return: String representing the Javascript Array of the object indexes (of class L{ref_class}) referencing a given object (L{obj_class}, L{obj_handle})
		"""
		bkref_list = self.bkref_dict[obj_class][obj_handle]
		if (not bkref_list): return ("[]")
		# Sort by referenced object
		bkref_list = sorted(bkref_list, key = lambda bkref: self.obj_dict[bkref[BKREF_CLASS]][bkref[BKREF_HANDLE]][OBJDICT_NAME])
		# Filter bkref_list (keep only ref_class) and remove duplicates
		seen = set()
		bkref_list = [bkref_handle
			for (bkref_class, bkref_handle, media_ref) in bkref_list
			if (bkref_class == ref_class and not (bkref_handle in seen or seen.add(bkref_handle)))]
		return("[" +
			",".join([str(self.obj_dict[ref_class][bkref_handle][OBJDICT_INDEX]) for bkref_handle in bkref_list]) +
			"]")


	def _data_repo_backref_index(self, repo, ref_class):
		"""
		Build a list of object referencing a given repository, in the form:
		 - object index (in table 'I', 'F', 'S')
		 - media type
		 - call number
		 - notes of the repository reference
		@param repo: Referenced repository
		@param ref_class: Class of the refencing objects
		@return: String representing the Javascript Array of the references to L{repo}
		"""
		repo_handle = repo.get_handle()
		if (repo_handle not in self.obj_dict[Repository]): return("[]")
		bkref_list = self.bkref_dict[Repository][repo_handle]
		if (not bkref_list): return ("[]")
		sep = ""
		txt = "["
		for (bkref_class, bkref_handle, repo_ref) in bkref_list:
			if (ref_class != bkref_class): continue
			i = self.obj_dict[ref_class][bkref_handle][OBJDICT_INDEX]
			object = self.get_object_from_handle(bkref_class, bkref_handle)
			txt += sep + self._data_repo_ref(repo_ref, i)
			sep = ","
		txt += "]"
		return(txt)

	def _data_media_backref_index(self, media, ref_class):
		"""
		Build a list of object referencing a given media, in the form:
		 - object index (in table 'I', 'F', 'S')
		 - media thumbnail path
		 - [x1, y1, x2, y2] of the media reference
		 - notes of the media reference
		 - list of the media reference source citations index (in table 'C')
		@param media: Referenced repository
		@param ref_class: Class of the refencing objects
		@return: String representing the Javascript Array of the references to L{media}
		"""
		media_handle = media.get_handle()
		if (media_handle not in self.obj_dict[MediaObject]): return("[]")
		bkref_list = self.bkref_dict[MediaObject][media_handle]
		if (not bkref_list): return ("[]")
		sep = ""
		txt = "["
		for (bkref_class, bkref_handle, media_ref) in bkref_list:
			if (ref_class != bkref_class): continue
			i = self.obj_dict[ref_class][bkref_handle][OBJDICT_INDEX]
			object = self.get_object_from_handle(bkref_class, bkref_handle)
			txt += sep + self._data_media_ref(media_ref, i)
			sep = ","
		txt += "]"
		return(txt)


	def get_object_from_handle(self, class_, handle):
		"""
		Get an object from its handle and class
		"""
		object = None
		if (class_ == Person):
			object = self.database.get_person_from_handle(handle)
		elif (class_ == Family):
			object = self.database.get_family_from_handle(handle)
		elif (class_ == Event):
			object = self.database.get_event_from_handle(handle)
		elif (class_ == Source):
			object = self.database.get_source_from_handle(handle)
		elif (class_ == Citation):
			object = self.database.get_citation_from_handle(handle)
		elif (class_ == Place):
			object = self.database.get_place_from_handle(handle)
		elif (class_ == Repository):
			object = self.database.get_repository_from_handle(handle)
		return(object)


	##############################################################################################
	################################################################################## GENDEX data
	##############################################################################################

	def build_gendex(self, ind_list):
		if (not self.inc_gendex): return
		fp_gendex = StringIO()
		for person_handle in ind_list:
			self.write_gendex(fp_gendex, person_handle)
		self.update_file("gendex.txt", fp_gendex.getvalue())

	def write_gendex(self, fp, person_handle):
		"""
		Reference|SURNAME|given name /SURNAME/|date of birth|place of birth|date of death|place of death|
		* field 1: file name of web page referring to the individual
		* field 2: surname of the individual
		* field 3: full name of the individual
		* field 4: date of birth or christening (optional)
		* field 5: place of birth or christening (optional)
		* field 6: date of death or burial (optional)
		* field 7: place of death or burial (optional) 
		"""
		if (not(person_handle and (person_handle in self.obj_dict[Person]))): return
		person = self.database.get_person_from_handle(person_handle)
		url = "person.html?idx=%i" % self.obj_dict[Person][person_handle][OBJDICT_INDEX]
		surname = person.get_primary_name().get_surname()
		fullname = person.get_primary_name().get_gedcom_name()
		
		# get birth info:
		(dob, pob) = self.get_gendex_data(person.get_birth_ref())
		
		# get death info:
		(dod, pod) = self.get_gendex_data(person.get_death_ref())
		fp.write(
			'|'.join((url, surname, fullname, dob, pob, dod, pod)) + '|\n')

	def get_gendex_data(self, event_ref):
		"""
		Given an event, return the date and place a strings
		"""
		doe = "" # date of event
		poe = "" # place of event
		if (event_ref):
			event = self.database.get_event_from_handle(event_ref.ref)
			if (event):
				date = event.get_date_object()
				doe = format_date(date, gedcom = True)
				if (event.get_place_handle()):
					place_handle = event.get_place_handle()
					if (place_handle):
						place = self.database.get_place_from_handle(place_handle)
						if (place):
							if (DWR_VERSION_412):
								poe = _pd.display(self.database, place)
							else:
								poe = place.get_title()
		return(doe, poe)
		

	##############################################################################################
	##############################################################################################
	#
	#                  Objects dictionaries construction
	#
	##############################################################################################
	##############################################################################################

	def _build_obj_dict(self):
		"""
		Construct the dictionaries of objects to be included in the reports. There
		are two dictionaries, which have the same structure: they are two level
		dictionaries,the first key is the class of object (e.g. gen.lib.Person).
		The second key is the handle of the object.

		For the obj_dict, the value is a tuple containing:
		 - the gramps_id
		 - the text name for the object
		 - the index (number starting at 0)

		For the bkref_dict, the value is a tuple containing:
		 - the class of object that refers to the 'key' object
		 - the handle for the object that refers to the 'key' object
		 - the reference object:
			- None in most cases
			- for media it is a MediaRef object
		
		This method recursively calls the methods "_add_***"
		"""
		_obj_class_list = (Person, Family, Event, Place, Source, Citation,
						   MediaObject, Repository, Note, Tag)

		# setup a dictionary of the required structure
		self.obj_dict = defaultdict(lambda: defaultdict(set))
		self.bkref_dict = defaultdict(lambda: defaultdict(set))


		# initialise the dictionary to empty in case no objects of any
		# particular class are included in the web report
		for obj_class in _obj_class_list:
			self.obj_dict[obj_class] = defaultdict(set)

		ind_list = self.database.iter_person_handles()
		with self.user.progress(_("Dynamic Web Site Report"),
								  _("Applying Person Filter..."),
								  self.database.get_number_of_people()) as step:
			ind_list = self.filter.apply(self.database, ind_list,
										 step)

		with self.user.progress(_("Dynamic Web Site Report"),
								  _("Constructing list of other objects..."),
								  sum(1 for _ in ind_list)) as step:
			for handle in ind_list:
				# FIXME work around bug that self.database.iter under python 3
				# returns (binary) data rather than text
				if (not isinstance(handle, UNITYPE)):
					handle = handle.decode("UTF-8")
				step()
				self._add_person(handle, "", "")

		log.debug("final object dictionary \n" +
				  "".join(("%s: %s\n" % item) for item in self.obj_dict.items()))

		log.debug("final backref dictionary \n" +
				  "".join(("%s: %s\n" % item) for item in self.bkref_dict.items()))


	def _add_person(self, person_handle, bkref_class, bkref_handle):
		"""
		Add person_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		# Update the dictionaries of objects back references
		self.bkref_dict[Person][person_handle].add((bkref_class, bkref_handle, None))
		# Check if the person is already added
		if (person_handle in self.obj_dict[Person]): return
		# Add person in the dictionaries of objects
		person = self.database.get_person_from_handle(person_handle)
		if (not person): return
		person_name = self.get_person_name(person)
		self.obj_dict[Person][person_handle] = [person_name, person.gramps_id, len(self.obj_dict[Person])]
		# Person events
		evt_ref_list = person.get_event_ref_list()
		if evt_ref_list:
			for evt_ref in evt_ref_list:
				self._add_event(evt_ref.ref, Person, person_handle, evt_ref)
		# Person citations
		for citation_handle in person.get_citation_list():
			self._add_citation(citation_handle, Person, person_handle)
		# Person name citations
		for name in [person.get_primary_name()] + \
						person.get_alternate_names():
			for citation_handle in name.get_citation_list():
				self._add_citation(citation_handle, Person, person_handle)
		# LDS Ordinance citations
		for lds_ord in person.get_lds_ord_list():
			for citation_handle in lds_ord.get_citation_list():
				self._add_citation(citation_handle, Person, person_handle)
		# Attribute citations
		for attr in person.get_attribute_list():
			for citation_handle in attr.get_citation_list():
				self._add_citation(citation_handle, Person, person_handle)
		# Person families
		family_handle_list = person.get_family_handle_list()
		if family_handle_list:
			for family_handle in person.get_family_handle_list():
				self._add_family(family_handle, Person, person_handle)
		# Person media
		for media_ref in person.get_media_list():
			media_handle = media_ref.get_reference_handle()
			self._add_media(media_handle, Person, person_handle, media_ref)
		# Association citations
		for assoc in person.get_person_ref_list():
			for citation_handle in assoc.get_citation_list():
				self._add_citation(citation_handle, Person, person_handle)
		# Addresses citations
		for addr in person.get_address_list():
			for citation_handle in addr.get_citation_list():
				self._add_citation(citation_handle, Person, person_handle)


	def get_person_name(self, person):
		"""
		Return a string containing the person's primary name in the name format chosen in the web report options
		@param: person -- person object from database
		"""
		name_format = self.options['name_format']
		primary_name = person.get_primary_name()
		name = Name(primary_name)
		name.set_display_as(name_format)
		return _nd.display_name(name)


	def _add_family(self, family_handle, bkref_class, bkref_handle):
		"""
		Add family_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		# Update the dictionaries of objects back references
		self.bkref_dict[Family][family_handle].add((bkref_class, bkref_handle, None))
		# Check if the family is already added
		if (family_handle in self.obj_dict[Family]): return
		# Add family in the dictionaries of objects
		family = self.database.get_family_from_handle(family_handle)
		family_name = self.get_family_name(family)
		self.obj_dict[Family][family_handle] = [family_name, family.gramps_id, len(self.obj_dict[Family])]
		# Family events
		evt_ref_list = family.get_event_ref_list()
		if evt_ref_list:
			for evt_ref in evt_ref_list:
				self._add_event(evt_ref.ref, Family, family_handle, evt_ref)
		# Family child references
		for child_ref in family.get_child_ref_list():
			for citation_handle in child_ref.get_citation_list():
				self._add_citation(citation_handle, Family, family_handle)
		# LDS Ordinance citations
		for lds_ord in family.get_lds_ord_list():
			for citation_handle in lds_ord.get_citation_list():
				self._add_citation(citation_handle, Family, family_handle)
		# Attributes citations
		for attr in family.get_attribute_list():
			for citation_handle in attr.get_citation_list():
				self._add_citation(citation_handle, Family, family_handle)
		# Family citations
		for citation_handle in family.get_citation_list():
			self._add_citation(citation_handle, Family, family_handle)
		# Family media
		for media_ref in family.get_media_list():
			media_handle = media_ref.get_reference_handle()
			self._add_media(media_handle, Family, family_handle, media_ref)


	def get_family_name(self, family):
		"""
		Return a string containing the name of the family (e.g. 'Family of John Doe and Jane Doe')
		@param: family -- family object from database
		"""
		husband_handle = family.get_father_handle()
		spouse_handle = family.get_mother_handle()

		husband = self.database.get_person_from_handle(husband_handle)
		spouse = self.database.get_person_from_handle(spouse_handle)

		if husband and spouse:
			husband_name = self.get_person_name(husband)
			spouse_name = self.get_person_name(spouse)
			title_str = _("Family of %(husband)s and %(spouse)s") % {
				"husband": husband_name,
				"spouse": spouse_name}
		elif husband:
			husband_name = self.get_person_name(husband)
			# Only the name of the husband is known
			title_str = _("Family of %(father)s") % {"father": husband_name}
		elif spouse:
			spouse_name = self.get_person_name(spouse)
			# Only the name of the wife is known
			title_str = _("Family of %(mother)s") % {"mother": spouse_name}
		else:
			title_str = ""

		return title_str


	def _add_event(self, event_handle, bkref_class, bkref_handle, event_ref):
		"""
		Add event_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		# Check if event reference already added
		refs = []
		if (event_handle in self.bkref_dict[Event]):
			refs = [bkref[BKREF_REFOBJ] for bkref in self.bkref_dict[Event][event_handle]]
			# The event reference is already recorded
			if (event_ref in refs): return
		# Update the dictionaries of objects back references
		self.bkref_dict[Event][event_handle].add((bkref_class, bkref_handle, event_ref))
		# Event reference attributes citations
		for attr in event_ref.get_attribute_list():
			for citation_handle in attr.get_citation_list():
				self._add_citation(citation_handle, bkref_class, bkref_handle)
		# Check if the event is already added
		if (event_handle in self.obj_dict[Event]): return
		# Add event in the dictionaries of objects
		event = self.database.get_event_from_handle(event_handle)
		if (not event): return
		event_name = str(event.get_type())
		event_desc = event.get_description()
		# The event description can be Y on import from GEDCOM. See the
		# following quote from the GEDCOM spec: "The occurrence of an event is
		# asserted by the presence of either a DATE tag and value or a PLACe tag
		# and value in the event structure. When neither the date value nor the
		# place value are known then a Y(es) value on the parent event tag line
		# is required to assert that the event happened.""
		if not (event_desc == "" or event_desc is None or event_desc =="Y"):
			event_name = event_name + ": " + event_desc
		self.obj_dict[Event][event_handle] = [event_name, event.gramps_id, len(self.obj_dict[Event])]
		# Event place
		place_handle = event.get_place_handle()
		if (place_handle):
			self._add_place(place_handle, bkref_class, bkref_handle)
		# Event citations
		for citation_handle in event.get_citation_list():
			self._add_citation(citation_handle, bkref_class, bkref_handle)
		# Event attributes citations
		for attr in event.get_attribute_list():
			for citation_handle in attr.get_citation_list():
				self._add_citation(citation_handle, bkref_class, bkref_handle)
		# Event media
		for media_ref in event.get_media_list():
			media_handle = media_ref.get_reference_handle()
			self._add_media(media_handle, bkref_class, bkref_handle, media_ref)


	def _add_place(self, place_handle, bkref_class, bkref_handle):
		"""
		Add place_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		# Update the dictionaries of objects back references
		self.bkref_dict[Place][place_handle].add((bkref_class, bkref_handle, None))
		# Check if the place is already added
		if (place_handle in self.obj_dict[Place]): return
		# Add place in the dictionaries of objects
		place = self.database.get_place_from_handle(place_handle)
		if (DWR_VERSION_412):
			place_name = _pd.display(self.database, place)
		else:
			place_name = place.get_title()
		self.obj_dict[Place][place_handle] = [place_name, place.gramps_id, len(self.obj_dict[Place])]

		if (self.inc_places):
			# Place citations
			for citation_handle in place.get_citation_list():
				self._add_citation(citation_handle, Place, place_handle)
			# Place media
			for media_ref in place.get_media_list():
				media_handle = media_ref.get_reference_handle()
				self._add_media(media_handle, Place, place_handle, media_ref)


	def _add_source(self, source_handle, bkref_class, bkref_handle):
		"""
		Add source_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		if (not self.inc_sources): return
		# Update the dictionaries of objects back references
		self.bkref_dict[Source][source_handle].add((bkref_class, bkref_handle, None))
		# Check if the source is already added
		if (source_handle in self.obj_dict[Source]): return
		# Add source in the dictionaries of objects
		source = self.database.get_source_from_handle(source_handle)
		source_name = source.get_title()
		self.obj_dict[Source][source_handle] = [source_name, source.gramps_id, len(self.obj_dict[Source])]
		# Source repository
		if self.inc_repositories:
			for repo_ref in source.get_reporef_list():
				repo_handle = repo_ref.get_reference_handle()
				self._add_repository(repo_handle, Source, source_handle, repo_ref)
		# Source media
		for media_ref in source.get_media_list():
			media_handle = media_ref.get_reference_handle()
			self._add_media(media_handle, Source, source_handle, media_ref)


	def _add_citation(self, citation_handle, bkref_class, bkref_handle):
		"""
		Add citation_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		if (not self.inc_sources): return
		# Update the dictionaries of objects back references
		self.bkref_dict[Citation][citation_handle].add((bkref_class, bkref_handle, None))
		# Check if the citation is already added
		if (citation_handle in self.obj_dict[Citation]): return
		# Add citation in the dictionaries of objects
		citation = self.database.get_citation_from_handle(citation_handle)
		citation_name = citation.get_page() or ""
		source_handle = citation.get_reference_handle()
		self.obj_dict[Citation][citation_handle] = [citation_name, citation.gramps_id, len(self.obj_dict[Citation])]
		# Citation source
		self._add_source(source_handle, Citation, citation_handle)
		# Citation media
		for media_ref in citation.get_media_list():
			media_handle = media_ref.get_reference_handle()
			self._add_media(media_handle, Source, source_handle, media_ref)


	def _add_media(self, media_handle, bkref_class, bkref_handle, media_ref):
		"""
		Add media_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		if (not self.inc_gallery): return
		# Check if media reference already added
		refs = []
		if (media_handle in self.bkref_dict[MediaObject]):
			refs = [bkref[BKREF_REFOBJ] for bkref in self.bkref_dict[MediaObject][media_handle]]
			# The media reference is already recorded
			if (media_ref in refs): return
		# Update the dictionaries of objects back references
		self.bkref_dict[MediaObject][media_handle].add((bkref_class, bkref_handle, media_ref))
		# Citations for media reference, media reference attributes
		citation_list = media_ref.get_citation_list()
		for attr in media_ref.get_attribute_list():
			citation_list.extend(attr.get_citation_list())
		for citation_handle in citation_list:
			self._add_citation(citation_handle, MediaObject, media_handle)
		# Check if the media is already added
		if (media_handle in self.obj_dict[MediaObject]): return
		# Add media in the dictionaries of objects
		media = self.database.get_object_from_handle(media_handle)
		media_name = "Media"
		self.obj_dict[MediaObject][media_handle] = [media_name, media.gramps_id, len(self.obj_dict[MediaObject])]
		# Citations for media, media attributes
		citation_list = media.get_citation_list()
		for attr in media.get_attribute_list():
			citation_list.extend(attr.get_citation_list())
		for citation_handle in citation_list:
			self._add_citation(citation_handle, MediaObject, media_handle)


	def _add_repository(self, repo_handle, bkref_class, bkref_handle, repo_ref):
		"""
		Add repo_handle to the L{self.obj_dict}, and recursively all referenced objects
		"""
		if (not self.inc_repositories): return
		# Check if repository reference already added
		refs = []
		if (repo_handle in self.bkref_dict[Repository]):
			refs = [bkref[BKREF_REFOBJ] for bkref in self.bkref_dict[Repository][repo_handle]]
			# The repository reference is already recorded
			if (repo_ref in refs): return
		# Update the dictionaries of objects back references
		self.bkref_dict[Repository][repo_handle].add((bkref_class, bkref_handle, repo_ref))
		# Check if the repository is already added
		if (repo_handle in self.obj_dict[Repository]): return
		# Add repository in the dictionaries of objects
		repo = self.database.get_repository_from_handle(repo_handle)
		repo_name = repo.name
		self.obj_dict[Repository][repo_handle] = [repo_name, repo.gramps_id, len(self.obj_dict[Repository])]
		# Addresses citations
		for addr in repo.get_address_list():
			for citation_handle in addr.get_citation_list():
				self._add_citation(citation_handle, Repository, repo_handle)

				
	##############################################################################################
	##############################################################################################
	#
	#                  Objects dictionaries sorting
	#
	##############################################################################################
	##############################################################################################


	def _sort_obj_dict(self):
		"""
		Sort the dictionaries of objects to be included in the reports.
		The dictionaries are sorted by name.
		The sorting is performed by modifying the index of the objects.
		"""
		
		# Sort persons
		sortkeys = {}
		objs = list(self.obj_dict[Person].keys())
		for handle in objs:
			sortkeys[handle] = self.get_person_name_sort_key(handle)
		objs.sort(key = lambda x: sortkeys[x])
		for (i, x) in enumerate(objs):
			self.obj_dict[Person][x][OBJDICT_INDEX] = i
			
		# Sort families
		sortkeys = {}
		objs = list(self.obj_dict[Family].keys())
		for handle in objs:
			sortkeys[handle] = self.get_family_name_sort_key(handle)
		objs.sort(key = lambda x: sortkeys[x])
		for (i, x) in enumerate(objs):
			self.obj_dict[Family][x][OBJDICT_INDEX] = i

		# Sort others
		for cls in (Source, Repository, MediaObject, Place):
			objs = list(self.obj_dict[cls].keys())
			sortkeys = {}
			for handle in objs:
				sortkeys[handle] = SORT_KEY(self.obj_dict[cls][handle][OBJDICT_NAME])
			objs.sort(key = lambda x: sortkeys[x])
			for (i, x) in enumerate(objs):
				self.obj_dict[cls][x][OBJDICT_INDEX] = i
		

	def get_person_name_sort_key(self, handle):
		"""
		Return a sort key for a person
		"""
		person = self.database.get_person_from_handle(handle)
		primary_name = person.get_primary_name()
		sort_str = _nd.sort_string(primary_name)
		return(SORT_KEY(sort_str))
		
		
	def get_family_name_sort_key(self, handle):
		"""
		Return a sort key for a family
		"""
		family = self.database.get_family_from_handle(handle)
		husband_handle = family.get_father_handle()
		spouse_handle = family.get_mother_handle()

		husband = self.database.get_person_from_handle(husband_handle)
		spouse = self.database.get_person_from_handle(spouse_handle)

		if husband and spouse:
			sort_key = self.get_person_name_sort_key(husband_handle) + SORT_KEY(" ") + self.get_person_name_sort_key(spouse_handle)
		elif husband:
			sort_key = self.get_person_name_sort_key(husband_handle)
		elif spouse:
			sort_key = self.get_person_name_sort_key(spouse_handle)
		else:
			sort_key = SORT_KEY("")

		return(sort_key)
		
		
		
		
##################################################################################################
##################################################################################################
#
#                            DynamicWebReport Menu Options
#
##################################################################################################
##################################################################################################

class DynamicWebOptions(MenuReportOptions):
	"""
	Creates the DynamicWebReport Menu Options
	Defines options and provides handling interface.
	
	Methods:
	- add_menu_options: called by Gramps to generate the options menu. It calls all the other methods "__add_***_options"
	- __add_***_options: One method for each tab of the options menu.
	- __***_changed: methods called when an option impacts other options
	"""
	def __init__(self, name, dbase):
	
		self.__db = dbase #: Gramps database
		
		# The data below are used when some options change the behavior of other options. For example: a boolean option enables/disables another option. These data are used in the methods "__***_changed".
		self.__pid = None
		self.__filter = None
		self.__living = None
		self.__yearsafterdeath = None
		
		#: This help explains how Gramps note are modified in order to generate custom pages
		self.note_help = _(
			"In this note, the following special words are processed:\n"
			"__SEARCH_FORM__ is replaced by a search form.\n"
			"__NB_INDIVIDUALS__ is replaced by the number of persons.\n"
			"__NB_FAMILIES__ is replaced by the number of families.\n"
			"__NB_MEDIA__ is replaced by the number of media objects.\n"
			"__NB_SOURCES__ is replaced by the number of sources.\n"
			"__NB_REPOSITORIES__ is replaced by the number of repositories.\n"
			"__NB_PLACES__ is replaced by the number of places.\n"
			"__MEDIA_<gid>__ is replaced by the media with gramps ID <gid>.\n"
			"__THUMB_<gid>__ is replaced by the thumbnail of the media with gramps ID <gid>.\n"
			"__EXPORT_DATE__ is replaced by the current date.\n"
			"__GRAMPS_VERSION__ is replaced by the GRAMPS version.\n"
			"__GRAMPS_HOMEPAGE__ is replaced by the GRAMPS homepage link.\n"
			"URL starting with \"relative://relative.<link>\" are replaced by the relative URL \"<link>\".\n")
			
		MenuReportOptions.__init__(self, name, dbase)

		
	def add_menu_options(self, menu):
		"""
		Add options to the menu for the web site.
		
		It calls all the other methods "__add_***_options" (one method for each tab of the options menu).
		"""
		self.__add_report_options(menu)
		self.__add_privacy_options(menu)
		self.__add_options_options(menu)
		self.__add_pages_advanced_options(menu)
		self.__add_pages_options(menu)
		self.__add_trees_options(menu)
		self.__add_custom_pages_options(menu)
		self.__add_select_pages_options(menu)

		
	def __add_report_options(self, menu):
		"""
		Options on the "Report" tab.
		"""
		category_name = _("Report")
		addopt = partial(menu.add_option, category_name)

		dbname = self.__db.get_dbname()
		default_dir = dbname + "_" + "dynamicweb"
		target = DestinationOption(_("Destination"),
			os.path.join(config.get("paths.website-directory"), default_dir))
		target.set_help(_("The destination directory for the web files"))
		target.set_directory_entry(True)
		addopt("target", target)

		self.__archive = BooleanOption(_('Store web pages in archive'), False)
		self.__archive.set_help(_("Whether to create an archive file (in ZIP or TGZ format) containing the web site"))
		addopt("archive", self.__archive)
		self.__archive.connect("value-changed", self.__archive_changed)

		self.__archive_file = DestinationOption(_("Archive file"),
			os.path.join(config.get("paths.website-directory"), default_dir, "archive.zip"))
		self.__archive_file.set_help(_("The archive file name (with \".zip\" or \".tgz\" extension)"))
		self.__archive_file.set_directory_entry(False)
		addopt("archive_file", self.__archive_file)

		self.__archive_changed()

		title = StringOption(_("Web site title"), _("My Family Tree"))
		title.set_help(_("The title of the web site"))
		addopt("title", title)

		self.__filter = FilterOption(_("Filter"), 0)
		self.__filter.set_help(
			   _("Select filter to restrict people that appear on web site"))
		addopt("filter", self.__filter)
		self.__filter.connect("value-changed", self.__filter_changed)

		self.__pid = PersonOption(_("Filter Person"))
		self.__pid.set_help(_("The center person for the filter"))
		addopt("pid", self.__pid)
		self.__pid.connect("value-changed", self.__pid_changed)

		self.__pid_changed()

		# We must figure out the value of the first option before we can create the EnumeratedListOption
		fmt_list = _nd.get_name_format()
		defaultnum = _nd.get_default_format()
		default = 0
		for ind, val in enumerate(fmt_list):
			if val[0] == defaultnum:
				default = ind
				break
		name_format = EnumeratedListOption(_("Name format"), fmt_list[default][0])
		for num, name, fmt_str, act in fmt_list:
			name_format.add_item(num, name)
		name_format.set_help(_("Select the format to display the complete names"))
		addopt("name_format", name_format)
		short_name_format = EnumeratedListOption(_("Name format (short)"), fmt_list[default][0])
		for num, name, fmt_str, act in fmt_list:
			short_name_format.add_item(num, name)
		short_name_format.set_help(_("Select the format to display a shorter version of the names"))
		addopt("short_name_format", short_name_format)
		
		template = EnumeratedListOption(_("Web site template"), 0)
		for (i, (directory, name)) in enumerate(WEB_TEMPLATE_LIST):
			template.add_item(i, name)
		template.set_help(_("Select the template of the web site"))
		addopt("template", template)

		cpright = EnumeratedListOption(_("Copyright"), 0)
		for index, copt in enumerate(_COPY_OPTIONS):
			cpright.add_item(index, copt)
		cpright.set_help( _("The copyright to be used for the web files"))
		addopt("copyright", cpright)


	def __add_privacy_options(self, menu):
		"""
		Options on the "Privacy" tab.
		"""
		category_name = _("Privacy")
		addopt = partial(menu.add_option, category_name)

		incpriv = BooleanOption(_("Include records marked private"), False)
		incpriv.set_help(_("Whether to include private objects"))
		addopt("incpriv", incpriv)

		inc_notes = BooleanOption(_("Export notes"), True)
		inc_notes.set_help(_("Whether to export notes in the web pages"))
		addopt("inc_notes", inc_notes)

		inc_sources = BooleanOption(_("Export sources"), True)
		inc_sources.set_help(_("Whether to export sources and citations in the web pages"))
		addopt("inc_sources", inc_sources)

		inc_addresses = BooleanOption(_("Export addresses"), True)
		inc_addresses.set_help(_("Whether to export addresses in the web pages"))
		addopt("inc_addresses", inc_addresses)

		self.__living = EnumeratedListOption(_("Living People"),
											 LivingProxyDb.MODE_EXCLUDE_ALL)
		self.__living.add_item(LivingProxyDb.MODE_EXCLUDE_ALL,
							   _("Exclude"))
		self.__living.add_item(LivingProxyDb.MODE_INCLUDE_LAST_NAME_ONLY,
							   _("Include Last Name Only"))
		self.__living.add_item(LivingProxyDb.MODE_INCLUDE_FULL_NAME_ONLY,
							   _("Include Full Name Only"))
		self.__living.add_item(INCLUDE_LIVING_VALUE,
							   _("Include"))
		self.__living.set_help(_("How to handle living people"))
		addopt("living", self.__living)
		self.__living.connect("value-changed", self.__living_changed)

		self.__yearsafterdeath = NumberOption(_("Years from death to consider "
												 "living"), 30, 0, 100)
		self.__yearsafterdeath.set_help(_("This allows you to restrict "
										  "information on people who have not "
										  "been dead for very long"))

		addopt("yearsafterdeath", self.__yearsafterdeath)

		self.__living_changed()


	def __add_options_options(self, menu):
		category_name = _("Options")
		addopt = partial(menu.add_option, category_name)

		inc_repositories = BooleanOption(_('Include repository pages'), False)
		inc_repositories.set_help(_('Whether or not to include the Repository Pages.'))
		addopt("inc_repositories", inc_repositories)

		inc_gallery = BooleanOption(_("Include images and media objects"), True)
		inc_gallery.set_help(_("Whether to include a media objects in the web pages"))
		addopt("inc_gallery", inc_gallery)

		copy_media = BooleanOption(_("Copy images and media objects"), True)
		copy_media.set_help(_("Whether to make a copy of the media objects."
			" When the objects are not copied, they are referenced by their relative path name"))
		addopt("copy_media", copy_media)

		print_notes_type = BooleanOption(_("Print the notes type"), True)
		print_notes_type.set_help(_("Whether to print the notes type in the notes text"))
		addopt("print_notes_type", print_notes_type)

		self.__inc_places = BooleanOption(_("Print place pages"), True)
		self.__inc_places.set_help(_("Whether to show pages for the places"))
		addopt("inc_places", self.__inc_places)
		self.__inc_places.connect("value-changed", self.__placemap_options_changed)

		self.__placemappages = BooleanOption(_("Include Place map on Place Pages"), False)
		self.__placemappages.set_help(_(
			"Whether to include a place map on the Place Pages, "
			"where Latitude/ Longitude are available."))
		self.__placemappages.connect("value-changed", self.__placemap_options_changed)
		addopt("placemappages", self.__placemappages)

		self.__familymappages = BooleanOption(_(
			"Include Family Map Pages with "
			"all places shown on the map"), False)
		self.__familymappages.set_help(_(
			"Whether or not to add an individual page map "
			"showing all the places on this page. "
			"This will allow you to see how your family "
			"traveled around the country."))
		self.__familymappages.connect("value-changed", self.__placemap_options_changed)
		addopt("familymappages", self.__familymappages)

		mapopts = [
			[_("Google"), "Google"],
			[_("OpenStreetMap"), "OpenStreetMap"]
		]
		self.__mapservice = EnumeratedListOption(_("Map Service"), mapopts[0][1])
		for trans, opt in mapopts:
			self.__mapservice.add_item(opt, trans)
		self.__mapservice.set_help(_("Choose your choice of map service for creating the Place Map Pages"))
		self.__mapservice.connect("value-changed", self.__placemap_options_changed)
		addopt("mapservice", self.__mapservice)

		self.__placemap_options_changed()


	def __add_pages_advanced_options(self, menu):
		category_name = _("Advanced")
		addopt = partial(menu.add_option, category_name)

		encoding = EnumeratedListOption(_('Character set encoding'), _CHARACTER_SETS[0][1])
		for eopt in _CHARACTER_SETS:
			encoding.add_item(eopt[1], eopt[0])
		encoding.set_help(_("The encoding to be used for the web files"))
		addopt("encoding", encoding)

		inc_families = BooleanOption(_("Include family pages"), False)
		inc_families.set_help(_("Whether or not to include family pages"))
		addopt("inc_families", inc_families)

		inc_events = BooleanOption(_('Include event pages'), False)
		inc_events.set_help(_('Add a complete events list and relevant pages or not'))
		addopt("inc_events", inc_events)
		inc_events.set_available(False)

		showbirth = BooleanOption(_("Include a column for birth dates on the index pages"), True)
		showbirth.set_help(_('Whether to include a birth column'))
		addopt("showbirth", showbirth)

		showdeath = BooleanOption(_("Include a column for death dates on the index pages"), False)
		showdeath.set_help(_('Whether to include a death column'))
		addopt("showdeath", showdeath)

		showmarriage = BooleanOption(_("Include a column for marriage dates on the index pages"), False)
		showmarriage.set_help(_('Whether to include a marriage column'))
		addopt("showmarriage", showmarriage)

		showpartner = BooleanOption(_("Include a column for partners on the index pages"), False)
		showpartner.set_help(_('Whether to include a partners column'))
		addopt("showpartner", showpartner)

		showparents = BooleanOption(_("Include a column for parents on the index pages"), False)
		showparents.set_help(_('Whether to include a parents column'))
		addopt("showparents", showparents)

		showallsiblings = BooleanOption(_("Include half and/ or step-siblings on the individual pages"), False)
		showallsiblings.set_help(_( "Whether to include half and/ or step-siblings with the parents and siblings"))
		addopt('showallsiblings', showallsiblings)

		birthorder = BooleanOption(_('Sort all children in birth order'), False)
		birthorder.set_help(_('Whether to display children in birth order or in entry order?'))
		addopt("birthorder", birthorder)

		bkref_type = BooleanOption(_('Include references in indexes'), False)
		bkref_type.set_help(_('Whether to include the references to the items in the index pages. For example, in the media index page, the names of the individuals, families, places, sources that reference the media.'))
		addopt("bkref_type", bkref_type)

		inc_gendex = BooleanOption(_('Include GENDEX file (/gendex.txt)'), False)
		inc_gendex.set_help(_('Whether to include a GENDEX file or not'))
		addopt("inc_gendex", inc_gendex)


	def __add_trees_options(self, menu):
		category_name = _("Trees")
		addopt = partial(menu.add_option, category_name)

		page_defs = [
			PAGE_SVG_TREE,
		]
		for page_def in page_defs:
			name = PAGES_NAMES[page_def][0]
			title = PAGES_NAMES[page_def][1]
			page_name = StringOption(_("Title for the tree \"%(name)s\"") % {"name": name}, title)
			page_name.set_help(_("Name for the page that shows the tree \"%(name)s\"") % {"name": name})
			addopt("page_name_%i" % page_def, page_name)

		graphgens = NumberOption(_("Maximum number of  generations"), 10, 3, 30)
		graphgens.set_help(_("The maximum number of generations to include in the ancestor and descendant trees and graphs"))
		addopt("graphgens", graphgens)

		svg_tree_type = EnumeratedListOption(_("SVG tree graph type"), str(DEFAULT_SVG_TREE_TYPE))
		for (i, opt) in enumerate(SVG_TREE_TYPES):
			svg_tree_type.add_item(str(i), opt)
		svg_tree_type.set_help(_("Choose the default SVG tree graph type"))
		addopt("svg_tree_type", svg_tree_type)
		
		svg_tree_shape = EnumeratedListOption(_("SVG tree graph shape"), str(DEFAULT_SVG_TREE_SHAPE))
		for (i, opt) in enumerate(SVG_TREE_SHAPES):
			svg_tree_shape.add_item(str(i), opt)
		svg_tree_shape.set_help(_("Choose the default SVG tree graph shape"))
		addopt("svg_tree_shape", svg_tree_shape)
		
		svg_tree_distrib_asc = EnumeratedListOption(_("SVG tree parents distribution"), str(DEFAULT_SVG_TREE_DISTRIB))
		for (i, opt) in enumerate(SVG_TREE_DISTRIB_ASC):
			svg_tree_distrib_asc.add_item(str(i), opt)
		svg_tree_distrib_asc.set_help(_("Choose the default SVG tree parents distribution (for fan charts only)"))
		addopt("svg_tree_distrib_asc", svg_tree_distrib_asc)
		
		svg_tree_distrib_dsc = EnumeratedListOption(_("SVG tree children distribution"), str(DEFAULT_SVG_TREE_DISTRIB))
		for (i, opt) in enumerate(SVG_TREE_DISTRIB_DSC):
			svg_tree_distrib_dsc.add_item(str(i), opt)
		svg_tree_distrib_dsc.set_help(_("Choose the default SVG tree children distribution (for fan charts only)"))
		addopt("svg_tree_distrib_dsc", svg_tree_distrib_dsc)
		
		svg_tree_background = EnumeratedListOption(_("Background"), str(DEFAULT_SVG_TREE_BACKGROUND))
		for (i, opt) in enumerate(SVG_TREE_BACKGROUNDS):
			svg_tree_background.add_item(str(i), opt)
		svg_tree_background.set_help(_("Choose the background color scheme for the persons in the SVG tree graph"))
		addopt("svg_tree_background", svg_tree_background)

		svg_tree_color1 = ColorOption(_("Start gradient/Main color"), "#EF2929")
		addopt("svg_tree_color1", svg_tree_color1)

		svg_tree_color2 = ColorOption(_("End gradient/2nd color"), "#3D37E9")
		addopt("svg_tree_color2", svg_tree_color2)

		self.__svg_tree_dup = BooleanOption(_("Show duplicates"), True)
		self.__svg_tree_dup.set_help(_("Whether to use a special color for the persons that appear several times in the SVG tree"))
		self.__svg_tree_dup.connect("value-changed", self.__svg_tree_dup_changed)
		addopt("svg_tree_dup", self.__svg_tree_dup)
		
		self.__svg_tree_color_dup = ColorOption(_("Color for duplicates"), "#888A85")
		addopt("svg_tree_color_dup", self.__svg_tree_color_dup)


	def __add_pages_options(self, menu):
		category_name = _("Pages")
		addopt = partial(menu.add_option, category_name)

		headernote = NoteOption(_('HTML user header'))
		headernote.set_help( _("A note to be used as the page header"))
		addopt("headernote", headernote)

		footernote = NoteOption(_('HTML user footer'))
		footernote.set_help( _("A note to be used as the page footer"))
		addopt("footernote", footernote)

		page_defs = [
			PAGE_PERSON,
			PAGE_SURNAMES,
			PAGE_PERSON_INDEX,
			PAGE_FAMILY_INDEX,
			PAGE_SOURCE_INDEX,
			PAGE_MEDIA_INDEX,
			PAGE_PLACE_INDEX,
			PAGE_ADDRESS_INDEX,
			PAGE_REPOSITORY_INDEX,
		]
		for page_def in page_defs:
			name = PAGES_NAMES[page_def][0]
			title = PAGES_NAMES[page_def][1]
			page_name = StringOption(_("Title for the page \"%(name)s\"") % {"name": name}, title)
			page_name.set_help(_("Name for the page \"%(name)s\"") % {"name": name})
			addopt("page_name_%i" % page_def, page_name)


	def __add_custom_pages_options(self, menu):
		category_name = _("Custom pages")
		addopt = partial(menu.add_option, category_name)

		for i in range(NB_CUSTOM_PAGES):
			page_def = PAGE_CUSTOM + i
			page_name = StringOption(_("Title for the custom page %(index)i") % {"index": i + 1}, _("Custom page %(index)i") % {"index": i + 1})
			page_name.set_help(_("Name for the custom page %(index)i") % {"index": i + 1})
			addopt("page_name_%i" % page_def, page_name)

			custom_note = NoteOption(_("Note for custom page %(index)i") % {"index": i + 1})
			custom_note.set_help(_("A note to be used for the custom page content.\n") + self.note_help)
			addopt("custom_note_%i" % i, custom_note)

			custom_menu = BooleanOption(_("Menu for the custom page %(index)i") % {"index": i + 1}, True)
			custom_menu.set_help(_("Whether to print a menu for the custom page"))
			addopt("custom_menu_%i" % i, custom_menu)


	def __add_select_pages_options(self, menu):
		category_name = _("Pages selection")
		addopt = partial(menu.add_option, category_name)

		self.__pages_number = NumberOption(_("Number of pages"), 11, 1, NB_TOTAL_PAGES_MAX)
		self.__pages_number.set_help(_("Number pages in the web site."))
		addopt("pages_number", self.__pages_number)
		self.__pages_number.connect("value-changed", self.__pages_contents_changed)

		page_defs = [
			PAGE_CUSTOM,
			PAGE_SURNAMES,
			PAGE_PERSON,
			PAGE_PERSON_INDEX,
			PAGE_FAMILY_INDEX,
			PAGE_SOURCE_INDEX,
			PAGE_MEDIA_INDEX,
			PAGE_PLACE_INDEX,
			PAGE_ADDRESS_INDEX,
			PAGE_REPOSITORY_INDEX,
			PAGE_SVG_TREE,
		] + [PAGE_CUSTOM + i for i in range (1, NB_CUSTOM_PAGES)
		] + [PAGE_CUSTOM] * NB_TOTAL_PAGES_MAX

		self.__page_content = []
		for i in range(NB_TOTAL_PAGES_MAX):
			page_def = page_defs[i]
			page_content = EnumeratedListOption(_("Contents of page %(index)i") % {"index": i + 1}, page_def)
			for (j, pname) in enumerate(PAGES_NAMES):
				page_content.add_item(j, pname[0])
			page_content.set_help(_("Contents of the page"))
			addopt("page_content_%i" % i, page_content)
			self.__page_content.append(page_content)
			self.__page_content[i].connect("value-changed", self.__pages_contents_changed)

		self.__pages_contents_changed()


	def __archive_changed(self):
		"""
		Disable the archive file when archive is disabled 
		"""
		enable = self.__archive.get_value()
		self.__archive_file.set_available(enable)

	def __pid_changed(self):
		"""
		Update the filter list based on the selected person
		"""
		gid = self.__pid.get_value()
		person = self.__db.get_person_from_gramps_id(gid)
		filter_list = report_utils.get_person_filters(person, False)
		self.__filter.set_filters(filter_list)

	def __filter_changed(self):
		"""
		Handle filter change. If the filter is not specific to a person,
		disable the person option
		"""
		filter_value = self.__filter.get_value()
		if filter_value in [1, 2, 3, 4]:
			# Filters 1, 2, 3 and 4 rely on the center person
			self.__pid.set_available(True)
		else:
			# The rest don't
			self.__pid.set_available(False)

	def __living_changed(self):
		"""
		Handle a change in the living option
		"""
		if self.__living.get_value() == INCLUDE_LIVING_VALUE:
			self.__yearsafterdeath.set_available(False)
		else:
			self.__yearsafterdeath.set_available(True)

	def __pages_contents_changed(self):
		nb = self.__pages_number.get_value()
		for i in range(NB_TOTAL_PAGES_MAX):
			if (i < nb):
				self.__page_content[i].set_available(True)
			else:
				self.__page_content[i].set_available(False)

	def __placemap_options_changed(self):
		"""
		Handles the changing nature of the place map Options
		"""
		# get values for all Place Map Options tab...
		place_active = self.__inc_places.get_value()
		place_map_active = self.__placemappages.get_value()
		family_active = self.__familymappages.get_value()
		mapservice_opts = self.__mapservice.get_value()
		# google_opts = self.__googleopts.get_value()

		if (place_active):
			self.__placemappages.set_available(True)
			self.__familymappages.set_available(True)
			self.__mapservice.set_available(True)
			# self.__googleopts.set_available(True)

		if (place_map_active or family_active):
			self.__mapservice.set_available(True)
		else:
			self.__mapservice.set_available(False)

		# if (family_active and mapservice_opts == "Google"):
			# self.__googleopts.set_available(True)
		# else:
			# self.__googleopts.set_available(False)

		if (not place_active):
			self.__placemappages.set_available(False)
			self.__familymappages.set_available(False)
			self.__mapservice.set_available(False)
			# self.__googleopts.set_available(False)

	def __svg_tree_dup_changed(self):
		"""
		Handles the duplicate color enable
		"""
		enable = self.__svg_tree_dup.get_value()
		self.__svg_tree_color_dup.set_available(enable)
